{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275c4dfb-c91e-454a-8cad-02df1d3048ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "\n",
    "# !pip install tensorflow scikit-learn pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1050c2a3-9345-4a07-8d95-68e21bd7d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection                  import train_test_split\n",
    "from tensorflow.keras.preprocessing.text      import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence  import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a99c5bdb-ee17-4f78-b637-cce0a7b08c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer as BaseTokenizer\n",
    "\n",
    "class Tokenizer(BaseTokenizer):\n",
    "    def __init__(self, num_words=None, oov_token=None, **kwargs):\n",
    "        super().__init__(num_words=num_words, oov_token=oov_token, **kwargs)\n",
    "        self.next_index = 1  # Initialize the index for unseen words\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            sequence = []\n",
    "            for word in text.split():\n",
    "                index = self.word_index.get(word)\n",
    "                # print(self.word_index)\n",
    "                if index is None:\n",
    "                    index = self.document_count\n",
    "                    self.word_index[word] = index\n",
    "                    self.index_word[index] = word\n",
    "                    self.document_count += 1\n",
    "                    # print(self.index_word)\n",
    "                sequence.append(index)\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b924ad6-2922-445f-a8be-001a7777abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "\n",
    "records = 2000\n",
    "params  = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99c1322-d1fc-40bc-b736-440d03323a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>meta_data</th>\n",
       "      <th>liked_keywords</th>\n",
       "      <th>priority_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artificial intelligence</td>\n",
       "      <td>Simulation of human intelligence processes by ...</td>\n",
       "      <td>technology future</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quantum mechanics</td>\n",
       "      <td>Description of nature at the smallest scales o...</td>\n",
       "      <td>physics quantum</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Renewable energy</td>\n",
       "      <td>Collection of energy from renewable resources.</td>\n",
       "      <td>environment sustainability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine learning</td>\n",
       "      <td>Development of algorithms and models for compu...</td>\n",
       "      <td>data algorithm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World War II</td>\n",
       "      <td>Global war involving many countries from 1939 ...</td>\n",
       "      <td>history military</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>Best podcasts for learning</td>\n",
       "      <td>Search for information about the best podcasts...</td>\n",
       "      <td>learning podcasts best</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Beginner crochet patterns</td>\n",
       "      <td>Search for beginner-friendly crochet patterns,...</td>\n",
       "      <td>crochet patterns beginner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>DIY natural hair care recipes</td>\n",
       "      <td>Search for do-it-yourself (DIY) natural hair c...</td>\n",
       "      <td>DIY hair care</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Famous contemporary artists</td>\n",
       "      <td>Search for information about famous contempora...</td>\n",
       "      <td>contemporary artists famous</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Indoor herb garden ideas</td>\n",
       "      <td>Search for ideas for creating an indoor herb g...</td>\n",
       "      <td>indoor herb garden ideas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             query  \\\n",
       "0          Artificial intelligence   \n",
       "1                Quantum mechanics   \n",
       "2                 Renewable energy   \n",
       "3                 Machine learning   \n",
       "4                     World War II   \n",
       "..                             ...   \n",
       "520     Best podcasts for learning   \n",
       "521      Beginner crochet patterns   \n",
       "522  DIY natural hair care recipes   \n",
       "523    Famous contemporary artists   \n",
       "524       Indoor herb garden ideas   \n",
       "\n",
       "                                             meta_data  \\\n",
       "0    Simulation of human intelligence processes by ...   \n",
       "1    Description of nature at the smallest scales o...   \n",
       "2       Collection of energy from renewable resources.   \n",
       "3    Development of algorithms and models for compu...   \n",
       "4    Global war involving many countries from 1939 ...   \n",
       "..                                                 ...   \n",
       "520  Search for information about the best podcasts...   \n",
       "521  Search for beginner-friendly crochet patterns,...   \n",
       "522  Search for do-it-yourself (DIY) natural hair c...   \n",
       "523  Search for information about famous contempora...   \n",
       "524  Search for ideas for creating an indoor herb g...   \n",
       "\n",
       "                  liked_keywords  priority_score  \n",
       "0              technology future               1  \n",
       "1                physics quantum               0  \n",
       "2     environment sustainability               1  \n",
       "3                 data algorithm               1  \n",
       "4               history military               0  \n",
       "..                           ...             ...  \n",
       "520       learning podcasts best               1  \n",
       "521    crochet patterns beginner               1  \n",
       "522                DIY hair care               1  \n",
       "523  contemporary artists famous               0  \n",
       "524     indoor herb garden ideas               1  \n",
       "\n",
       "[525 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('dataset/Meta -2.csv')\n",
    "\n",
    "def func(x):\n",
    "    return ' '.join(\n",
    "        x[2:-2].split(\"', '\")\n",
    "    )\n",
    "data['liked_keywords'] = data['liked_keywords'].apply(func)\n",
    "data['priority_score'] /= 100\n",
    "\n",
    "data['priority_score'] = data['priority_score'].apply(lambda x: 1 if x > 0.7 else 0)\n",
    "data\n",
    "# print(help(data['priority_score'].apply))\n",
    "# data['priority_score'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f6daec2-d208-433b-baa0-a9ea664ce28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525, 1000) (525, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# data = pd.read_csv('dataset/Meta -2.csv')\n",
    "\n",
    "data = data[:records]\n",
    "\n",
    "# print(tokenizer, dir(tokenizer))\n",
    "# Assuming `data` is a DataFrame with columns 'query', 'likes', and 'priority_percentage'\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=None)\n",
    "tokenizer.fit_on_texts(data['query'] + ' ' + data['liked_keywords'])\n",
    "\n",
    "# Convert text to sequences\n",
    "query_sequences = tokenizer.texts_to_sequences(data['query'])\n",
    "likes_sequences = tokenizer.texts_to_sequences(data['liked_keywords'])\n",
    "\n",
    "# Pad sequences\n",
    "query_padded = pad_sequences(query_sequences, padding='post', maxlen = params)\n",
    "likes_padded = pad_sequences(likes_sequences, padding='post', maxlen = params)\n",
    "\n",
    "\n",
    "print(query_padded.shape, likes_padded.shape)\n",
    "# print(data[['query', 'liked_keywords', 'priority_score']], query_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a31d4cb0-8965-4940-aafd-65dc42941391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_sequences\n",
    "# data['query'][0]\n",
    "# tokenizer.texts_to_sequences([data['query'][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeab91d4-5773-4c86-b032-17c39dcd9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Concatenate, SimpleRNN, Dense\n",
    "\n",
    "# # Define the model architecture\n",
    "# query_input = Input(shape=(params,), dtype='int32')\n",
    "# likes_input = Input(shape=(params,), dtype='int32')\n",
    "\n",
    "# # Embedding layers for both inputs\n",
    "# query_embedding = Embedding(input_dim=params, output_dim=128)(query_input)\n",
    "# likes_embedding = Embedding(input_dim=params, output_dim=128)(likes_input)\n",
    "\n",
    "# # Concatenate the embeddings\n",
    "# merged = Concatenate()([query_embedding, likes_embedding])\n",
    "# # \n",
    "# # Simple RNN layer\n",
    "# rnn_layer = Dense(128)(merged)\n",
    "\n",
    "# # Dense layer for regression\n",
    "# output = Dense(1)(rnn_layer)\n",
    "\n",
    "# # Compile the model\n",
    "# model = Model(inputs=[query_input, likes_input], outputs=output)\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=['accuracy', 'precision', 'recall', 'f1_score'])\n",
    "# print(query_padded.shape, likes_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f21662-7b6a-4862-854d-0576ef87a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layers for website metadata and user past liked keywords\n",
    "website_metadata_input = Input(shape=(params,))\n",
    "user_liked_keywords_input = Input(shape=(params,))\n",
    "\n",
    "# Concatenate the inputs\n",
    "concatenated_inputs = Concatenate()([website_metadata_input, user_liked_keywords_input])\n",
    "\n",
    "# Dense layers\n",
    "dense1 = Dense(512, activation='relu')(concatenated_inputs)\n",
    "dense2 = Dense(256, activation='relu')(dense1)\n",
    "output = Dense(1, activation='sigmoid')(dense2)  # Output layer with sigmoid activation for binary classification\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[website_metadata_input, user_liked_keywords_input], outputs=output)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "560e4a4d-701c-4ddc-9fb2-7e6f9cd24ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024,512</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m1,024,512\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,156,097</span> (4.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,156,097\u001b[0m (4.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,156,097</span> (4.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,156,097\u001b[0m (4.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir(model)\n",
    "model.summary()\n",
    "# help(model.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60630994-da06-4bb5-b793-7c2787218ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.3082\n",
      "Epoch 2/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 0.3778\n",
      "Epoch 3/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7811 - loss: 0.5376\n",
      "Epoch 4/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8969 - loss: 0.2965\n",
      "Epoch 5/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8426 - loss: 0.3938\n",
      "Epoch 6/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8714 - loss: 0.3173\n",
      "Epoch 7/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8842 - loss: 0.3258\n",
      "Epoch 8/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8918 - loss: 0.3265\n",
      "Epoch 9/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8746 - loss: 0.3026\n",
      "Epoch 10/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.3162\n",
      "Epoch 11/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8851 - loss: 0.2901\n",
      "Epoch 12/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8635 - loss: 0.3785\n",
      "Epoch 13/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.3492\n",
      "Epoch 14/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8688 - loss: 0.3387\n",
      "Epoch 15/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8443 - loss: 0.3465\n",
      "Epoch 16/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8653 - loss: 0.3500\n",
      "Epoch 17/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8842 - loss: 0.2853\n",
      "Epoch 18/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8943 - loss: 0.2823\n",
      "Epoch 19/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.4426\n",
      "Epoch 20/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8766 - loss: 0.3052\n",
      "Epoch 21/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8639 - loss: 0.3177\n",
      "Epoch 22/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8527 - loss: 0.3453\n",
      "Epoch 23/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8583 - loss: 0.3343\n",
      "Epoch 24/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 0.3654\n",
      "Epoch 25/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.3377\n",
      "Epoch 26/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8786 - loss: 0.3591\n",
      "Epoch 27/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7861 - loss: 0.4625\n",
      "Epoch 28/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8695 - loss: 0.3328\n",
      "Epoch 29/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8732 - loss: 0.3147\n",
      "Epoch 30/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.2914\n",
      "Epoch 31/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8776 - loss: 0.3268\n",
      "Epoch 32/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8821 - loss: 0.2786\n",
      "Epoch 33/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9005 - loss: 0.3059\n",
      "Epoch 34/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8975 - loss: 0.2538\n",
      "Epoch 35/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.2660\n",
      "Epoch 36/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8955 - loss: 0.2544\n",
      "Epoch 37/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8835 - loss: 0.3090\n",
      "Epoch 38/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8820 - loss: 0.2753\n",
      "Epoch 39/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2280\n",
      "Epoch 40/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.2539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x360859070>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "model.fit([query_padded, likes_padded], data['priority_score'], epochs=40, batch_size=32)\n",
    "# print(model.metrics_names)\n",
    "# model.evaluate([query_padded, likes_padded], data['priority_score'], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cc17ca0-fac8-4109-b68b-b8ec4ac8840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# saving tokenizer\n",
    "with open(\"../models/tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, )\n",
    "\n",
    "# loading\n",
    "with open('../models/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9272cc4-a173-446c-80ca-70ada1e4747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[822, 305, 83, 823, 824, 825]]\n",
      "822 helllooooo\n",
      "305 interaction\n",
      "83 a\n",
      "823 b\n",
      "824 c\n",
      "825 d\n"
     ]
    }
   ],
   "source": [
    "res = tokenizer1.texts_to_sequences(['helllooooo interaction a b c d'])\n",
    "print(res)\n",
    "for i in res[0]:\n",
    "    print(i, tokenizer1.index_word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5d1c7b9-2c49-4f40-a03c-b28c0ac5bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.2484651e-01],\n",
       "       [7.0187557e-01],\n",
       "       [7.2275007e-01],\n",
       "       [8.8063699e-01],\n",
       "       [3.3822632e-01],\n",
       "       [9.8511159e-01],\n",
       "       [8.6288750e-01],\n",
       "       [7.0685393e-01],\n",
       "       [9.5232385e-01],\n",
       "       [6.3268512e-01],\n",
       "       [9.9306858e-01],\n",
       "       [8.4554267e-01],\n",
       "       [9.6838653e-01],\n",
       "       [8.8409346e-01],\n",
       "       [3.1651208e-01],\n",
       "       [7.1892136e-01],\n",
       "       [9.7525585e-01],\n",
       "       [8.4272933e-01],\n",
       "       [9.7844470e-01],\n",
       "       [7.9100430e-01],\n",
       "       [9.3903053e-01],\n",
       "       [9.5665002e-01],\n",
       "       [7.3512936e-01],\n",
       "       [9.2919183e-01],\n",
       "       [9.2641413e-01],\n",
       "       [7.9135466e-01],\n",
       "       [9.9684155e-01],\n",
       "       [3.5716301e-01],\n",
       "       [9.3634087e-01],\n",
       "       [9.8888373e-01],\n",
       "       [9.9158055e-01],\n",
       "       [9.6054828e-01],\n",
       "       [7.3603272e-01],\n",
       "       [9.6494806e-01],\n",
       "       [5.6697166e-01],\n",
       "       [9.6585608e-01],\n",
       "       [9.9878281e-01],\n",
       "       [9.6743619e-01],\n",
       "       [9.6803105e-01],\n",
       "       [9.9193215e-01],\n",
       "       [9.9056375e-01],\n",
       "       [8.0710405e-01],\n",
       "       [7.7961957e-01],\n",
       "       [9.1531259e-01],\n",
       "       [5.4189903e-01],\n",
       "       [9.5184678e-01],\n",
       "       [9.7061425e-01],\n",
       "       [9.0879345e-01],\n",
       "       [8.7851882e-01],\n",
       "       [1.8713558e-01],\n",
       "       [8.0309963e-01],\n",
       "       [8.6369568e-01],\n",
       "       [9.7733414e-01],\n",
       "       [8.1592602e-01],\n",
       "       [9.5677894e-01],\n",
       "       [3.7807515e-01],\n",
       "       [9.9945349e-01],\n",
       "       [9.8506969e-01],\n",
       "       [9.7593659e-01],\n",
       "       [8.2384634e-01],\n",
       "       [5.9611017e-01],\n",
       "       [6.2165719e-01],\n",
       "       [8.2326913e-01],\n",
       "       [3.5253504e-01],\n",
       "       [9.6582413e-01],\n",
       "       [9.9187165e-01],\n",
       "       [9.7577333e-01],\n",
       "       [7.3753524e-01],\n",
       "       [9.9949229e-01],\n",
       "       [4.4927623e-02],\n",
       "       [9.2409813e-01],\n",
       "       [9.3675917e-01],\n",
       "       [9.0040475e-01],\n",
       "       [8.3282125e-01],\n",
       "       [9.8833811e-01],\n",
       "       [9.1003168e-01],\n",
       "       [9.8907822e-01],\n",
       "       [9.9981678e-01],\n",
       "       [8.9250857e-01],\n",
       "       [2.9429543e-01],\n",
       "       [9.5377433e-01],\n",
       "       [8.8386655e-01],\n",
       "       [9.5047307e-01],\n",
       "       [9.9887383e-01],\n",
       "       [7.3970312e-01],\n",
       "       [8.6055982e-01],\n",
       "       [9.8769033e-01],\n",
       "       [5.6937349e-01],\n",
       "       [8.0476046e-01],\n",
       "       [9.1799879e-01],\n",
       "       [9.9714315e-01],\n",
       "       [8.3796507e-01],\n",
       "       [9.3758130e-01],\n",
       "       [8.0540365e-01],\n",
       "       [9.0393180e-01],\n",
       "       [8.0573094e-01],\n",
       "       [9.7639430e-01],\n",
       "       [9.0073276e-01],\n",
       "       [8.8398057e-01],\n",
       "       [8.8866293e-01],\n",
       "       [8.9827073e-01],\n",
       "       [8.3201057e-01],\n",
       "       [8.2225722e-01],\n",
       "       [9.3599343e-01],\n",
       "       [9.2677075e-01],\n",
       "       [8.4706706e-01],\n",
       "       [9.1175795e-01],\n",
       "       [9.0678614e-01],\n",
       "       [9.1910166e-01],\n",
       "       [9.9892116e-01],\n",
       "       [9.3817103e-01],\n",
       "       [6.8826944e-01],\n",
       "       [7.6660246e-01],\n",
       "       [1.0705461e-01],\n",
       "       [9.9893260e-01],\n",
       "       [9.9015027e-01],\n",
       "       [8.5166955e-01],\n",
       "       [9.7996855e-01],\n",
       "       [9.9002618e-01],\n",
       "       [9.9077064e-01],\n",
       "       [9.9960649e-01],\n",
       "       [6.7807608e-03],\n",
       "       [9.9999946e-01],\n",
       "       [9.9162930e-01],\n",
       "       [8.8265586e-01],\n",
       "       [9.9999988e-01],\n",
       "       [9.9999988e-01],\n",
       "       [1.1334550e-01],\n",
       "       [8.8828200e-01],\n",
       "       [9.9999988e-01],\n",
       "       [9.9684942e-01],\n",
       "       [9.8990226e-01],\n",
       "       [8.9859569e-01],\n",
       "       [8.4312242e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9289089e-01],\n",
       "       [9.6801668e-01],\n",
       "       [9.9995106e-01],\n",
       "       [9.9999970e-01],\n",
       "       [1.2577951e-01],\n",
       "       [9.1646439e-01],\n",
       "       [9.9201542e-01],\n",
       "       [1.0705461e-01],\n",
       "       [9.9893260e-01],\n",
       "       [9.9015027e-01],\n",
       "       [8.5166955e-01],\n",
       "       [9.7996855e-01],\n",
       "       [7.1009600e-01],\n",
       "       [9.9987483e-01],\n",
       "       [9.5858985e-01],\n",
       "       [9.2938298e-01],\n",
       "       [9.9243575e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9981427e-01],\n",
       "       [9.2902976e-01],\n",
       "       [1.1047844e-01],\n",
       "       [9.9988353e-01],\n",
       "       [9.8890203e-01],\n",
       "       [9.4319016e-01],\n",
       "       [9.9783534e-01],\n",
       "       [9.9999988e-01],\n",
       "       [1.1411600e-01],\n",
       "       [9.3956155e-01],\n",
       "       [8.4560704e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9987614e-01],\n",
       "       [9.9815267e-01],\n",
       "       [1.0650798e-03],\n",
       "       [7.3906147e-01],\n",
       "       [9.9525326e-01],\n",
       "       [9.4920099e-01],\n",
       "       [8.5437369e-01],\n",
       "       [1.0000000e+00],\n",
       "       [6.3830364e-01],\n",
       "       [9.5787805e-01],\n",
       "       [9.8630190e-01],\n",
       "       [2.3185658e-01],\n",
       "       [2.6436231e-01],\n",
       "       [5.4773891e-01],\n",
       "       [8.6685908e-01],\n",
       "       [9.1449094e-01],\n",
       "       [9.9620903e-01],\n",
       "       [8.3722866e-01],\n",
       "       [9.1306257e-01],\n",
       "       [5.5215657e-01],\n",
       "       [7.8490305e-01],\n",
       "       [1.0000000e+00],\n",
       "       [7.8356630e-01],\n",
       "       [8.8419926e-01],\n",
       "       [9.9999654e-01],\n",
       "       [7.4410045e-01],\n",
       "       [9.9969918e-01],\n",
       "       [9.6251667e-01],\n",
       "       [9.6189624e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.4793206e-01],\n",
       "       [9.1591859e-01],\n",
       "       [9.6552020e-01],\n",
       "       [9.9543017e-01],\n",
       "       [9.6861297e-01],\n",
       "       [9.9789459e-01],\n",
       "       [9.1654611e-01],\n",
       "       [2.5517452e-01],\n",
       "       [9.2287076e-01],\n",
       "       [8.8469714e-01],\n",
       "       [5.7072651e-01],\n",
       "       [9.1277111e-01],\n",
       "       [9.9670559e-01],\n",
       "       [9.9996924e-01],\n",
       "       [8.7887192e-01],\n",
       "       [9.9613464e-01],\n",
       "       [9.8891371e-01],\n",
       "       [9.7174776e-01],\n",
       "       [9.9954957e-01],\n",
       "       [6.5415964e-04],\n",
       "       [9.9999547e-01],\n",
       "       [1.0000000e+00],\n",
       "       [8.3103728e-01],\n",
       "       [9.9571663e-01],\n",
       "       [9.7295117e-01],\n",
       "       [8.4371185e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.2742419e-01],\n",
       "       [9.6189624e-01],\n",
       "       [9.9999881e-01],\n",
       "       [9.4793206e-01],\n",
       "       [9.1591859e-01],\n",
       "       [9.6552020e-01],\n",
       "       [9.9543017e-01],\n",
       "       [9.9985337e-01],\n",
       "       [9.9789459e-01],\n",
       "       [9.1654611e-01],\n",
       "       [2.5517452e-01],\n",
       "       [9.2287076e-01],\n",
       "       [8.8469714e-01],\n",
       "       [9.8963267e-01],\n",
       "       [8.1022686e-01],\n",
       "       [9.8742139e-01],\n",
       "       [5.7072651e-01],\n",
       "       [9.4396323e-01],\n",
       "       [9.9485248e-01],\n",
       "       [9.9914163e-01],\n",
       "       [5.5126107e-01],\n",
       "       [9.9999928e-01],\n",
       "       [1.3889312e-02],\n",
       "       [9.9996197e-01],\n",
       "       [9.6976817e-01],\n",
       "       [8.6032224e-01],\n",
       "       [9.7405577e-01],\n",
       "       [9.7336513e-01],\n",
       "       [5.9533403e-03],\n",
       "       [9.9989396e-01],\n",
       "       [9.9899840e-01],\n",
       "       [9.5131534e-01],\n",
       "       [9.0297282e-01],\n",
       "       [9.7114378e-01],\n",
       "       [7.7266067e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.1924477e-01],\n",
       "       [9.9106246e-01],\n",
       "       [9.7292423e-01],\n",
       "       [7.6770538e-01],\n",
       "       [8.6759413e-03],\n",
       "       [9.4217497e-01],\n",
       "       [9.9987000e-01],\n",
       "       [9.8619461e-01],\n",
       "       [9.9940354e-01],\n",
       "       [9.0613759e-01],\n",
       "       [9.7340906e-01],\n",
       "       [9.6138263e-01],\n",
       "       [9.9999213e-01],\n",
       "       [8.5247064e-01],\n",
       "       [9.0731132e-01],\n",
       "       [9.7144401e-01],\n",
       "       [6.6578728e-01],\n",
       "       [9.9888182e-01],\n",
       "       [9.3248796e-01],\n",
       "       [9.9963713e-01],\n",
       "       [9.7349268e-01],\n",
       "       [9.8219419e-01],\n",
       "       [8.8223312e-03],\n",
       "       [9.2295790e-01],\n",
       "       [9.5135021e-01],\n",
       "       [9.0954179e-01],\n",
       "       [9.8300403e-01],\n",
       "       [9.8377579e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9896336e-01],\n",
       "       [9.1448319e-01],\n",
       "       [9.5409650e-01],\n",
       "       [9.5754123e-01],\n",
       "       [9.1294265e-01],\n",
       "       [9.5485318e-01],\n",
       "       [9.3849289e-01],\n",
       "       [9.9055564e-01],\n",
       "       [9.7380620e-01],\n",
       "       [9.9845672e-01],\n",
       "       [8.1988710e-01],\n",
       "       [9.4743288e-01],\n",
       "       [9.4858676e-01],\n",
       "       [8.9592904e-01],\n",
       "       [9.9793077e-01],\n",
       "       [8.5820633e-01],\n",
       "       [9.4182068e-01],\n",
       "       [9.0864432e-01],\n",
       "       [9.5312679e-01],\n",
       "       [9.1970450e-01],\n",
       "       [9.3749672e-01],\n",
       "       [9.9850297e-01],\n",
       "       [9.5351416e-01],\n",
       "       [8.6294121e-01],\n",
       "       [9.2245239e-01],\n",
       "       [9.4783777e-01],\n",
       "       [9.4898093e-01],\n",
       "       [8.9709258e-01],\n",
       "       [2.3824433e-02],\n",
       "       [9.4101667e-01],\n",
       "       [9.2113578e-01],\n",
       "       [9.9394238e-01],\n",
       "       [8.5817784e-01],\n",
       "       [9.4818968e-01],\n",
       "       [8.9475501e-01],\n",
       "       [9.9788690e-01],\n",
       "       [9.4859749e-01],\n",
       "       [8.6296886e-01],\n",
       "       [8.7568015e-01],\n",
       "       [9.9099672e-01],\n",
       "       [8.9391232e-01],\n",
       "       [9.9092513e-01],\n",
       "       [9.2636418e-01],\n",
       "       [9.9997956e-01],\n",
       "       [9.0011024e-01],\n",
       "       [9.2624891e-01],\n",
       "       [9.9778736e-01],\n",
       "       [9.8656648e-01],\n",
       "       [4.2212749e-09],\n",
       "       [9.2633456e-01],\n",
       "       [9.9177706e-01],\n",
       "       [9.0712100e-01],\n",
       "       [9.2637712e-01],\n",
       "       [9.9953634e-01],\n",
       "       [8.0932426e-04],\n",
       "       [9.2641991e-01],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [9.9969774e-01],\n",
       "       [9.9970192e-01],\n",
       "       [9.1196883e-01],\n",
       "       [9.9872226e-01],\n",
       "       [9.0430844e-01],\n",
       "       [9.3099457e-01],\n",
       "       [7.9395795e-01],\n",
       "       [9.9977571e-01],\n",
       "       [3.1288295e-05],\n",
       "       [9.9999923e-01],\n",
       "       [9.9749416e-01],\n",
       "       [9.9933857e-01],\n",
       "       [9.0019852e-01],\n",
       "       [9.9758959e-01],\n",
       "       [3.4914989e-02],\n",
       "       [9.1814780e-01],\n",
       "       [9.9991882e-01],\n",
       "       [8.2825065e-01],\n",
       "       [9.9977344e-01],\n",
       "       [1.0000000e+00],\n",
       "       [3.3485377e-01],\n",
       "       [9.2102623e-01],\n",
       "       [9.9965334e-01],\n",
       "       [9.8948812e-01],\n",
       "       [9.1335255e-01],\n",
       "       [9.0301502e-01],\n",
       "       [3.3485377e-01],\n",
       "       [9.2102623e-01],\n",
       "       [9.9965334e-01],\n",
       "       [9.8948812e-01],\n",
       "       [9.1335255e-01],\n",
       "       [9.0301502e-01],\n",
       "       [3.3485377e-01],\n",
       "       [9.2102623e-01],\n",
       "       [9.9965334e-01],\n",
       "       [9.8948812e-01],\n",
       "       [9.1335255e-01],\n",
       "       [9.0301502e-01],\n",
       "       [8.7686938e-01],\n",
       "       [9.4364959e-01],\n",
       "       [8.7822115e-01],\n",
       "       [8.7867963e-01],\n",
       "       [9.4401604e-01],\n",
       "       [8.7959224e-01],\n",
       "       [8.8004643e-01],\n",
       "       [9.4438356e-01],\n",
       "       [8.8094991e-01],\n",
       "       [9.4462734e-01],\n",
       "       [8.8184774e-01],\n",
       "       [9.4486988e-01],\n",
       "       [8.8279963e-01],\n",
       "       [9.4511169e-01],\n",
       "       [1.3293409e-01],\n",
       "       [9.4523215e-01],\n",
       "       [9.9999917e-01],\n",
       "       [9.9974102e-01],\n",
       "       [9.9995553e-01],\n",
       "       [9.9999535e-01],\n",
       "       [7.3557234e-01],\n",
       "       [9.9975300e-01],\n",
       "       [9.9999923e-01],\n",
       "       [9.9974793e-01],\n",
       "       [9.9995375e-01],\n",
       "       [9.9999493e-01],\n",
       "       [7.4050337e-01],\n",
       "       [5.4491705e-01],\n",
       "       [9.9999630e-01],\n",
       "       [9.9974817e-01],\n",
       "       [5.4045516e-01],\n",
       "       [9.9983174e-01],\n",
       "       [5.3802073e-01],\n",
       "       [9.5670635e-01],\n",
       "       [9.9021274e-01],\n",
       "       [9.9999130e-01],\n",
       "       [5.4045486e-01],\n",
       "       [5.3999156e-01],\n",
       "       [5.4236799e-01],\n",
       "       [9.9999624e-01],\n",
       "       [9.9041438e-01],\n",
       "       [9.9999624e-01],\n",
       "       [9.9999136e-01],\n",
       "       [7.4517387e-01],\n",
       "       [8.3832562e-01],\n",
       "       [9.9999619e-01],\n",
       "       [8.5218668e-01],\n",
       "       [7.4695712e-01],\n",
       "       [9.9999118e-01],\n",
       "       [9.9999619e-01],\n",
       "       [3.6885876e-02],\n",
       "       [1.0000000e+00],\n",
       "       [9.9595445e-01],\n",
       "       [9.5568049e-01],\n",
       "       [9.9692088e-01],\n",
       "       [9.9999994e-01],\n",
       "       [9.7802806e-01],\n",
       "       [9.7701603e-01],\n",
       "       [8.0338776e-01],\n",
       "       [9.5232284e-01],\n",
       "       [9.9780524e-01],\n",
       "       [9.9991685e-01],\n",
       "       [9.9734491e-01],\n",
       "       [9.9864250e-01],\n",
       "       [3.0897376e-03],\n",
       "       [9.9904019e-01],\n",
       "       [9.9957758e-01],\n",
       "       [9.9991494e-01],\n",
       "       [9.9502790e-01],\n",
       "       [9.9998975e-01],\n",
       "       [8.3582956e-05],\n",
       "       [9.9668729e-01],\n",
       "       [9.9764246e-01],\n",
       "       [9.9137700e-01],\n",
       "       [9.1854793e-01],\n",
       "       [9.8594999e-01],\n",
       "       [7.3105025e-01],\n",
       "       [9.9925917e-01],\n",
       "       [9.9721366e-01],\n",
       "       [9.9697447e-01],\n",
       "       [9.9794191e-01],\n",
       "       [7.3651892e-01],\n",
       "       [4.2677328e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.6720904e-01],\n",
       "       [9.8902708e-01],\n",
       "       [9.8485214e-01],\n",
       "       [9.9999899e-01],\n",
       "       [1.5920235e-04],\n",
       "       [9.9504656e-01],\n",
       "       [9.9934548e-01],\n",
       "       [9.4629431e-01],\n",
       "       [6.8997544e-01],\n",
       "       [9.9418348e-01],\n",
       "       [6.9038427e-01],\n",
       "       [8.6560494e-01],\n",
       "       [3.6885876e-02],\n",
       "       [1.0000000e+00],\n",
       "       [9.9595445e-01],\n",
       "       [9.5568049e-01],\n",
       "       [9.9692088e-01],\n",
       "       [9.9999994e-01],\n",
       "       [9.7802806e-01],\n",
       "       [9.7701603e-01],\n",
       "       [8.0338776e-01],\n",
       "       [9.5232284e-01],\n",
       "       [9.9780524e-01],\n",
       "       [9.9991685e-01],\n",
       "       [9.9734491e-01],\n",
       "       [9.9864250e-01],\n",
       "       [3.0897376e-03],\n",
       "       [9.9904019e-01],\n",
       "       [9.9957758e-01],\n",
       "       [9.9991494e-01],\n",
       "       [9.9502790e-01],\n",
       "       [9.9998975e-01],\n",
       "       [8.3582956e-05],\n",
       "       [9.9668729e-01],\n",
       "       [9.9764246e-01],\n",
       "       [9.9137700e-01],\n",
       "       [9.1854793e-01],\n",
       "       [9.8594999e-01],\n",
       "       [7.3105025e-01],\n",
       "       [9.9925917e-01],\n",
       "       [9.9721366e-01],\n",
       "       [9.9697447e-01],\n",
       "       [9.9794191e-01],\n",
       "       [7.3651892e-01],\n",
       "       [4.2677328e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.6720904e-01],\n",
       "       [9.8902708e-01],\n",
       "       [9.8485214e-01],\n",
       "       [9.9999899e-01],\n",
       "       [1.5920235e-04],\n",
       "       [9.9504656e-01],\n",
       "       [9.9934548e-01],\n",
       "       [9.4629431e-01],\n",
       "       [6.8997544e-01],\n",
       "       [9.9418348e-01],\n",
       "       [6.9038427e-01],\n",
       "       [8.6560494e-01]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([query_padded, likes_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "249d777f-2aca-453d-b668-22d2ac2a40b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.2520  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21710094809532166, 0.9104762077331543]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([query_padded, likes_padded], data['priority_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ef5c4b94-a5d8-49ff-a83e-88768017ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hello.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dae7f438-17f6-4140-8892-9c439cecf0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'of': 2,\n",
       " 'history': 3,\n",
       " 'indian': 4,\n",
       " 'tips': 5,\n",
       " 'for': 6,\n",
       " 'games': 7,\n",
       " 'disney': 8,\n",
       " 'kids': 9,\n",
       " 'goddess': 10,\n",
       " 'tv': 11,\n",
       " 'diy': 12,\n",
       " 'movies': 13,\n",
       " 'hinduism': 14,\n",
       " 'lord': 15,\n",
       " 'recipes': 16,\n",
       " 'hindu': 17,\n",
       " 'travel': 18,\n",
       " 'symptoms': 19,\n",
       " 'treatment': 20,\n",
       " 'famous': 21,\n",
       " 'music': 22,\n",
       " 'india': 23,\n",
       " 'video': 24,\n",
       " 'to': 25,\n",
       " 'shows': 26,\n",
       " 'beginner': 27,\n",
       " 'science': 28,\n",
       " 'how': 29,\n",
       " 'influence': 30,\n",
       " 'best': 31,\n",
       " 'the': 32,\n",
       " 'home': 33,\n",
       " 'lego': 34,\n",
       " 'learning': 35,\n",
       " 'animals': 36,\n",
       " 'building': 37,\n",
       " 'causes': 38,\n",
       " 'empire': 39,\n",
       " 'series': 40,\n",
       " 'toys': 41,\n",
       " 'ideas': 42,\n",
       " 'ancient': 43,\n",
       " 'temples': 44,\n",
       " 'shiva': 45,\n",
       " 'krishna': 46,\n",
       " 'indoor': 47,\n",
       " 'easy': 48,\n",
       " 'in': 49,\n",
       " 'songs': 50,\n",
       " 'quantum': 51,\n",
       " 'education': 52,\n",
       " 'singer': 53,\n",
       " 'animal': 54,\n",
       " 'stories': 55,\n",
       " 'puja': 56,\n",
       " 'biology': 57,\n",
       " 'culture': 58,\n",
       " 'art': 59,\n",
       " 'cartoons': 60,\n",
       " 'videos': 61,\n",
       " 'sets': 62,\n",
       " 'chemistry': 63,\n",
       " 'health': 64,\n",
       " 'engineering': 65,\n",
       " 'philosophy': 66,\n",
       " 'books': 67,\n",
       " 'mathematics': 68,\n",
       " 'geography': 69,\n",
       " 'prevention': 70,\n",
       " 'coloring': 71,\n",
       " 'yoga': 72,\n",
       " 'dance': 73,\n",
       " 'diabetes': 74,\n",
       " 'arthritis': 75,\n",
       " 'textiles': 76,\n",
       " 'god': 77,\n",
       " 'lakshmi': 78,\n",
       " 'vishnu': 79,\n",
       " 'kali': 80,\n",
       " 'radha': 81,\n",
       " 'sita': 82,\n",
       " 'mantra': 83,\n",
       " 'a': 84,\n",
       " 'hiking': 85,\n",
       " 'trails': 86,\n",
       " 'decor': 87,\n",
       " 'organizing': 88,\n",
       " 'natural': 89,\n",
       " 'impressionist': 90,\n",
       " 'painters': 91,\n",
       " 'homemade': 92,\n",
       " 'destinations': 93,\n",
       " 'garden': 94,\n",
       " 'classic': 95,\n",
       " 'patterns': 96,\n",
       " 'artists': 97,\n",
       " 'care': 98,\n",
       " 'economics': 99,\n",
       " 'europe': 100,\n",
       " 'and': 101,\n",
       " 'artifacts': 102,\n",
       " 'architecture': 103,\n",
       " 'facts': 104,\n",
       " 'characters': 105,\n",
       " 'activities': 106,\n",
       " 'hypertension': 107,\n",
       " 'prevent': 108,\n",
       " 'technology': 109,\n",
       " 'physics': 110,\n",
       " 'environment': 111,\n",
       " 'psychology': 112,\n",
       " 'society': 113,\n",
       " 'theory': 114,\n",
       " 'magic': 115,\n",
       " 'tricks': 116,\n",
       " 'experiments': 117,\n",
       " 'cooking': 118,\n",
       " 'online': 119,\n",
       " 'classes': 120,\n",
       " 'what': 121,\n",
       " 'is': 122,\n",
       " \"alzheimer's\": 123,\n",
       " 'anxiety': 124,\n",
       " 'allergies': 125,\n",
       " 'stroke': 126,\n",
       " 'osteoporosis': 127,\n",
       " 'copd': 128,\n",
       " 'spices': 129,\n",
       " 'forms': 130,\n",
       " 'significance': 131,\n",
       " 'epics': 132,\n",
       " 'durga': 133,\n",
       " 'rama': 134,\n",
       " 'saraswati': 135,\n",
       " 'hanuman': 136,\n",
       " 'parvati': 137,\n",
       " 'brahma': 138,\n",
       " 'murugan': 139,\n",
       " 'knitting': 140,\n",
       " 'growing': 141,\n",
       " 'behavior': 142,\n",
       " 'space': 143,\n",
       " 'exercise': 144,\n",
       " 'cultural': 145,\n",
       " 'language': 146,\n",
       " 'ethics': 147,\n",
       " 'money': 148,\n",
       " 'design': 149,\n",
       " 'educational': 150,\n",
       " 'comedy': 151,\n",
       " 'friends': 152,\n",
       " 'animation': 153,\n",
       " 'junior': 154,\n",
       " 'crafts': 155,\n",
       " 'gods': 156,\n",
       " 'data': 157,\n",
       " 'anthropology': 158,\n",
       " 'linguistics': 159,\n",
       " 'ecology': 160,\n",
       " 'disease': 161,\n",
       " 'industrial': 162,\n",
       " 'social': 163,\n",
       " 'development': 164,\n",
       " 'studies': 165,\n",
       " 'multiplayer': 166,\n",
       " 'fantasy': 167,\n",
       " 'minecraft': 168,\n",
       " 'star': 169,\n",
       " 'wars': 170,\n",
       " 'jokes': 171,\n",
       " 'channel': 172,\n",
       " 'projects': 173,\n",
       " 'heart': 174,\n",
       " 'asthma': 175,\n",
       " 'pneumonia': 176,\n",
       " 'depression': 177,\n",
       " 'cancer': 178,\n",
       " 'back': 179,\n",
       " 'pain': 180,\n",
       " 'independence': 181,\n",
       " 'gupta': 182,\n",
       " 'british': 183,\n",
       " 'maurya': 184,\n",
       " 'trade': 185,\n",
       " 'ram': 186,\n",
       " 'bhajan': 187,\n",
       " 'symbolism': 188,\n",
       " 'scarf': 189,\n",
       " 'rockies': 190,\n",
       " 'mediterranean': 191,\n",
       " 'diet': 192,\n",
       " 'tomatoes': 193,\n",
       " 'indoors': 194,\n",
       " 'small': 195,\n",
       " 'closet': 196,\n",
       " 'poses': 197,\n",
       " 'skincare': 198,\n",
       " 'gardening': 199,\n",
       " 'pasta': 200,\n",
       " 'digital': 201,\n",
       " 'files': 202,\n",
       " 'make': 203,\n",
       " 'candles': 204,\n",
       " 'making': 205,\n",
       " 'improving': 206,\n",
       " 'posture': 207,\n",
       " 'foodies': 208,\n",
       " 'photography': 209,\n",
       " 'renovation': 210,\n",
       " 'works': 211,\n",
       " 'shakespeare': 212,\n",
       " 'start': 213,\n",
       " 'vegetable': 214,\n",
       " 'starting': 215,\n",
       " 'saving': 216,\n",
       " 'groceries': 217,\n",
       " 'novels': 218,\n",
       " 'read': 219,\n",
       " 'must': 220,\n",
       " 'dessert': 221,\n",
       " 'better': 222,\n",
       " 'sleep': 223,\n",
       " 'budget': 224,\n",
       " 'cleaning': 225,\n",
       " 'modern': 226,\n",
       " 'succulents': 227,\n",
       " 'soap': 228,\n",
       " 'workout': 229,\n",
       " 'programs': 230,\n",
       " 'surrealist': 231,\n",
       " 'plant': 232,\n",
       " 'painting': 233,\n",
       " 'beauty': 234,\n",
       " 'products': 235,\n",
       " 'paintings': 236,\n",
       " 'compost': 237,\n",
       " 'pile': 238,\n",
       " 'watch': 239,\n",
       " 'vegetarian': 240,\n",
       " 'decluttering': 241,\n",
       " 'podcasts': 242,\n",
       " 'crochet': 243,\n",
       " 'hair': 244,\n",
       " 'contemporary': 245,\n",
       " 'herb': 246,\n",
       " 'mechanics': 247,\n",
       " 'civilization': 248,\n",
       " 'human': 249,\n",
       " 'astronomy': 250,\n",
       " 'computer': 251,\n",
       " 'planets': 252,\n",
       " 'robotics': 253,\n",
       " 'logic': 254,\n",
       " 'literature': 255,\n",
       " 'dinosaurs': 256,\n",
       " 'neuroscience': 257,\n",
       " 'brain': 258,\n",
       " 'system': 259,\n",
       " 'city': 260,\n",
       " 'computational': 261,\n",
       " 'cinema': 262,\n",
       " 'movement': 263,\n",
       " 'civilizations': 264,\n",
       " 'architectural': 265,\n",
       " 'superheroes': 266,\n",
       " 'taylor': 267,\n",
       " 'swift': 268,\n",
       " 'usa': 269,\n",
       " 'sci': 270,\n",
       " 'fi': 271,\n",
       " 'rapper': 272,\n",
       " 'mario': 273,\n",
       " 'pages': 274,\n",
       " \"children's\": 275,\n",
       " 'pixar': 276,\n",
       " 'nintendo': 277,\n",
       " 'family': 278,\n",
       " 'toddlers': 279,\n",
       " 'sounds': 280,\n",
       " 'on': 281,\n",
       " 'list': 282,\n",
       " 'apps': 283,\n",
       " 'impact': 284,\n",
       " 'festival': 285,\n",
       " 'renewable': 286,\n",
       " 'energy': 287,\n",
       " 'sustainability': 288,\n",
       " 'mind': 289,\n",
       " 'archaeology': 290,\n",
       " 'big': 291,\n",
       " 'markets': 292,\n",
       " 'molecules': 293,\n",
       " 'nutrition': 294,\n",
       " 'stars': 295,\n",
       " 'civil': 296,\n",
       " 'genetics': 297,\n",
       " 'environmental': 298,\n",
       " 'sociology': 299,\n",
       " 'geometry': 300,\n",
       " 'teaching': 301,\n",
       " 'linguistic': 302,\n",
       " 'optimization': 303,\n",
       " 'game': 304,\n",
       " 'security': 305,\n",
       " 'interaction': 306,\n",
       " 'urban': 307,\n",
       " 'criminal': 308,\n",
       " 'forensic': 309,\n",
       " 'cognitive': 310,\n",
       " 'media': 311,\n",
       " 'behavioral': 312,\n",
       " 'industry': 313,\n",
       " 'aerospace': 314,\n",
       " 'business': 315,\n",
       " 'avengers': 316,\n",
       " 'endgame': 317,\n",
       " 'fortnite': 318,\n",
       " 'paris': 319,\n",
       " 'france': 320,\n",
       " 'witcher': 321,\n",
       " 'stranger': 322,\n",
       " 'things': 323,\n",
       " 'beyoncé': 324,\n",
       " 'spain': 325,\n",
       " 'harry': 326,\n",
       " 'potter': 327,\n",
       " 'simulation': 328,\n",
       " 'marvel': 329,\n",
       " 'super': 330,\n",
       " 'asia': 331,\n",
       " 'pokémon': 332,\n",
       " 'cast': 333,\n",
       " 'prehistoric': 334,\n",
       " 'rhymes': 335,\n",
       " 'humor': 336,\n",
       " 'reading': 337,\n",
       " 'paw': 338,\n",
       " 'patrol': 339,\n",
       " 'baby': 340,\n",
       " 'cute': 341,\n",
       " 'pj': 342,\n",
       " 'masks': 343,\n",
       " 'sesame': 344,\n",
       " 'street': 345,\n",
       " 'solar': 346,\n",
       " 'toy': 347,\n",
       " 'story': 348,\n",
       " 'ninjago': 349,\n",
       " 'disneyland': 350,\n",
       " 'children': 351,\n",
       " 'habitats': 352,\n",
       " 'princess': 353,\n",
       " 'karaoke': 354,\n",
       " 'bedtime': 355,\n",
       " 'virtual': 356,\n",
       " 'tours': 357,\n",
       " 'flu': 358,\n",
       " 'migraine': 359,\n",
       " 'attack': 360,\n",
       " 'mughal': 361,\n",
       " 'raj': 362,\n",
       " 'buddhism': 363,\n",
       " 'freedom': 364,\n",
       " 'fighters': 365,\n",
       " 'sikhism': 366,\n",
       " 'vijayanagara': 367,\n",
       " 'leaders': 368,\n",
       " 'ocean': 369,\n",
       " 'chola': 370,\n",
       " 'colonization': 371,\n",
       " 'indus': 372,\n",
       " 'valley': 373,\n",
       " 'heritage': 374,\n",
       " 'maratha': 375,\n",
       " 'ashoka': 376,\n",
       " 'styles': 377,\n",
       " 'indo': 378,\n",
       " 'greek': 379,\n",
       " 'kingdom': 380,\n",
       " 'delhi': 381,\n",
       " 'sultanate': 382,\n",
       " 'women': 383,\n",
       " 'classical': 384,\n",
       " 'rajputs': 385,\n",
       " 'cuisine': 386,\n",
       " 'decline': 387,\n",
       " 'dynasty': 388,\n",
       " 'routes': 389,\n",
       " 'ganesha': 390,\n",
       " 'lingam': 391,\n",
       " 'ritual': 392,\n",
       " 'avatars': 393,\n",
       " 'chalisa': 394,\n",
       " 'creator': 395,\n",
       " 'aarti': 396,\n",
       " 'festivals': 397,\n",
       " 'childhood': 398,\n",
       " 'knit': 399,\n",
       " 'grow': 400,\n",
       " 'everyone': 401,\n",
       " 'should': 402,\n",
       " 'friendly': 403,\n",
       " 'your': 404,\n",
       " 'artificial': 405,\n",
       " 'intelligence': 406,\n",
       " 'future': 407,\n",
       " 'machine': 408,\n",
       " 'algorithm': 409,\n",
       " 'world': 410,\n",
       " 'war': 411,\n",
       " 'ii': 412,\n",
       " 'military': 413,\n",
       " 'climate': 414,\n",
       " 'change': 415,\n",
       " 'global': 416,\n",
       " 'warming': 417,\n",
       " 'analytics': 418,\n",
       " 'anatomy': 419,\n",
       " 'body': 420,\n",
       " 'exploration': 421,\n",
       " 'nasa': 422,\n",
       " 'microeconomics': 423,\n",
       " 'political': 424,\n",
       " 'government': 425,\n",
       " 'policy': 426,\n",
       " 'organic': 427,\n",
       " 'carbon': 428,\n",
       " 'european': 429,\n",
       " 'programming': 430,\n",
       " 'coding': 431,\n",
       " 'software': 432,\n",
       " 'fitness': 433,\n",
       " 'structures': 434,\n",
       " 'construction': 435,\n",
       " 'traditions': 436,\n",
       " 'grammar': 437,\n",
       " 'evolutionary': 438,\n",
       " 'species': 439,\n",
       " 'languages': 440,\n",
       " 'script': 441,\n",
       " 'translation': 442,\n",
       " 'automation': 443,\n",
       " 'pollution': 444,\n",
       " 'poetry': 445,\n",
       " 'paleontology': 446,\n",
       " 'fossils': 447,\n",
       " 'dna': 448,\n",
       " 'inheritance': 449,\n",
       " 'excavation': 450,\n",
       " 'numbers': 451,\n",
       " 'maps': 452,\n",
       " 'landforms': 453,\n",
       " 'matter': 454,\n",
       " 'elements': 455,\n",
       " 'compounds': 456,\n",
       " 'zoology': 457,\n",
       " 'organisms': 458,\n",
       " 'botany': 459,\n",
       " 'plants': 460,\n",
       " 'ecosystems': 461,\n",
       " 'events': 462,\n",
       " 'eras': 463,\n",
       " 'nervous': 464,\n",
       " 'buildings': 465,\n",
       " 'marine': 466,\n",
       " 'oceans': 467,\n",
       " 'aquatic': 468,\n",
       " 'life': 469,\n",
       " 'public': 470,\n",
       " 'geology': 471,\n",
       " 'rocks': 472,\n",
       " 'earthquakes': 473,\n",
       " 'consciousness': 474,\n",
       " 'systems': 475,\n",
       " 'strategic': 476,\n",
       " 'cybersecurity': 477,\n",
       " 'fashion': 478,\n",
       " 'clothing': 479,\n",
       " 'style': 480,\n",
       " 'computing': 481,\n",
       " 'planning': 482,\n",
       " 'bioinformatics': 483,\n",
       " 'genomics': 484,\n",
       " 'scientific': 485,\n",
       " 'method': 486,\n",
       " 'film': 487,\n",
       " 'operations': 488,\n",
       " 'research': 489,\n",
       " 'musical': 490,\n",
       " 'composition': 491,\n",
       " 'harmony': 492,\n",
       " 'cryptography': 493,\n",
       " 'encryption': 494,\n",
       " 'developmental': 495,\n",
       " 'child': 496,\n",
       " 'aging': 497,\n",
       " 'rights': 498,\n",
       " 'equality': 499,\n",
       " 'justice': 500,\n",
       " 'communication': 501,\n",
       " 'mass': 502,\n",
       " 'vision': 503,\n",
       " 'image': 504,\n",
       " 'processing': 505,\n",
       " 'ai': 506,\n",
       " 'semantics': 507,\n",
       " 'product': 508,\n",
       " 'particles': 509,\n",
       " 'interactions': 510,\n",
       " 'usability': 511,\n",
       " 'organizational': 512,\n",
       " 'organization': 513,\n",
       " 'workplace': 514,\n",
       " 'archaeoastronomy': 515,\n",
       " 'biochemistry': 516,\n",
       " 'morphology': 517,\n",
       " 'biomechanics': 518,\n",
       " 'cognition': 519,\n",
       " 'green': 520,\n",
       " 'geopolitics': 521,\n",
       " 'politics': 522,\n",
       " 'mathematical': 523,\n",
       " 'crime': 524,\n",
       " 'evidence': 525,\n",
       " 'field': 526,\n",
       " 'urbanization': 527,\n",
       " 'astrophysics': 528,\n",
       " 'cosmology': 529,\n",
       " 'medical': 530,\n",
       " 'medicine': 531,\n",
       " 'religious': 532,\n",
       " 'religion': 533,\n",
       " 'string': 534,\n",
       " 'information': 535,\n",
       " 'computers': 536,\n",
       " 'revolution': 537,\n",
       " 'work': 538,\n",
       " 'community': 539,\n",
       " 'counseling': 540,\n",
       " 'algebraic': 541,\n",
       " 'topology': 542,\n",
       " 'algebra': 543,\n",
       " 'resource': 544,\n",
       " 'management': 545,\n",
       " 'food': 546,\n",
       " 'economic': 547,\n",
       " 'cell': 548,\n",
       " 'cells': 549,\n",
       " 'ed': 550,\n",
       " 'sheeran': 551,\n",
       " 'new': 552,\n",
       " 'york': 553,\n",
       " 'fiction': 554,\n",
       " 'call': 555,\n",
       " 'duty': 556,\n",
       " 'shooting': 557,\n",
       " 'ariana': 558,\n",
       " 'grande': 559,\n",
       " 'tokyo': 560,\n",
       " 'japan': 561,\n",
       " 'mandalorian': 562,\n",
       " 'fifa': 563,\n",
       " '22': 564,\n",
       " 'sports': 565,\n",
       " 'rome': 566,\n",
       " 'italy': 567,\n",
       " 'black': 568,\n",
       " 'mirror': 569,\n",
       " 'among': 570,\n",
       " 'us': 571,\n",
       " 'drake': 572,\n",
       " 'london': 573,\n",
       " 'england': 574,\n",
       " 'office': 575,\n",
       " 'overwatch': 576,\n",
       " 'shooter': 577,\n",
       " 'billie': 578,\n",
       " 'eilish': 579,\n",
       " 'barcelona': 580,\n",
       " 'breaking': 581,\n",
       " 'bad': 582,\n",
       " 'drama': 583,\n",
       " 'league': 584,\n",
       " 'legends': 585,\n",
       " 'moba': 586,\n",
       " 'post': 587,\n",
       " 'malone': 588,\n",
       " 'sydney': 589,\n",
       " 'australia': 590,\n",
       " 'crossing': 591,\n",
       " 'hawaii': 592,\n",
       " 'zelda': 593,\n",
       " 'adventure': 594,\n",
       " 'pop': 595,\n",
       " 'genre': 596,\n",
       " 'dubai': 597,\n",
       " 'uae': 598,\n",
       " 'sims': 599,\n",
       " 'eminem': 600,\n",
       " 'greece': 601,\n",
       " 'thrones': 602,\n",
       " 'platformer': 603,\n",
       " 'adele': 604,\n",
       " 'thailand': 605,\n",
       " 'simpsons': 606,\n",
       " 'anime': 607,\n",
       " 'coldplay': 608,\n",
       " 'band': 609,\n",
       " 'brazil': 610,\n",
       " 'south': 611,\n",
       " 'america': 612,\n",
       " 'bang': 613,\n",
       " 'lady': 614,\n",
       " 'gaga': 615,\n",
       " 'china': 616,\n",
       " 'episodes': 617,\n",
       " 'kart': 618,\n",
       " 'racing': 619,\n",
       " 'cartoon': 620,\n",
       " 'network': 621,\n",
       " 'dinosaur': 622,\n",
       " 'spongebob': 623,\n",
       " 'squarepants': 624,\n",
       " 'nursery': 625,\n",
       " 'princesses': 626,\n",
       " 'cards': 627,\n",
       " 'craft': 628,\n",
       " 'switch': 629,\n",
       " 'with': 630,\n",
       " 'lyrics': 631,\n",
       " 'rides': 632,\n",
       " 'attractions': 633,\n",
       " 'themepark': 634,\n",
       " 'thomas': 635,\n",
       " 'netflix': 636,\n",
       " 'streaming': 637,\n",
       " 'fun': 638,\n",
       " 'riddles': 639,\n",
       " 'printable': 640,\n",
       " 'at': 641,\n",
       " 'app': 642,\n",
       " 'dress': 643,\n",
       " 'up': 644,\n",
       " 'batman': 645,\n",
       " 'preschoolers': 646,\n",
       " 'movie': 647,\n",
       " 'marathon': 648,\n",
       " 'outdoor': 649,\n",
       " 'outdoors': 650,\n",
       " 'sheets': 651,\n",
       " 'technic': 652,\n",
       " 'high': 653,\n",
       " 'blood': 654,\n",
       " 'pressure': 655,\n",
       " 'great': 656}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "570538aa-aa03-464c-8251-761db4194a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.saving.save_model(model, '../models/model_final.keras', overwrite=True)\n",
    "# loaded_model = keras.saving.load_model(\"model1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "cf77c2cb-3610-4558-9190-d1388ece3edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.53092307],\n",
       "       [0.53092664],\n",
       "       [0.5309242 ],\n",
       "       ...,\n",
       "       [0.53092647],\n",
       "       [0.5309263 ],\n",
       "       [0.5309273 ]], dtype=float32)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict([query_padded, likes_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194c6f1-1e76-4c27-a4b0-3dabec35d5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1848cd38-fa13-42cb-bbb3-fcde1e27b918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep tonight indeed war per.\n",
      "28 28\n",
      "Wonder common.\n",
      "14 14\n",
      "Anyone people cell fill.\n",
      "24 24\n",
      "Collection theory beat.\n",
      "23 23\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    q = data['query'][i]\n",
    "    print(q)\n",
    "    seq = tokenizer.texts_to_sequences(q)\n",
    "    pad = pad_sequences(seq)\n",
    "    print(len(seq), len(pad))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9beb5-594b-4638-9fde-529e68a68c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a68506cd-1a02-43a9-b9b0-e03969048b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(['sleep', 'hello', 'good', 'bb'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fdabb011-9708-4aaa-9c6e-ff6aeca5ffc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1]]\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Tokenizer\", \"config\": {\"num_words\": 10000, \"filters\": \"!\\\\\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n\", \"lower\": true, \"split\": \" \", \"char_level\": false, \"oov_token\": \"<OOV>\", \"document_count\": 4, \"word_counts\": \"{\\\\\"sleep\\\\\": 1, \\\\\"hello\\\\\": 1, \\\\\"good\\\\\": 1, \\\\\"bb\\\\\": 1}\", \"word_docs\": \"{\\\\\"sleep\\\\\": 1, \\\\\"hello\\\\\": 1, \\\\\"good\\\\\": 1, \\\\\"bb\\\\\": 1}\", \"index_docs\": \"{\\\\\"2\\\\\": 1, \\\\\"3\\\\\": 1, \\\\\"4\\\\\": 1, \\\\\"5\\\\\": 1}\", \"index_word\": \"{\\\\\"1\\\\\": \\\\\"baddddjjkj\\\\\", \\\\\"2\\\\\": \\\\\"sleep\\\\\", \\\\\"3\\\\\": \\\\\"hello\\\\\", \\\\\"4\\\\\": \\\\\"good\\\\\", \\\\\"5\\\\\": \\\\\"bb\\\\\"}\", \"word_index\": \"{\\\\\"<OOV>\\\\\": 1, \\\\\"sleep\\\\\": 2, \\\\\"hello\\\\\": 3, \\\\\"good\\\\\": 4, \\\\\"bb\\\\\": 5, \\\\\"baddddjjkj\\\\\": 1}\"}}'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.texts_to_sequences(['good baddddjjkj']))\n",
    "print(tokenizer.document_count)\n",
    "tokenizer.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "747df5eb-5a84-4b20-8dc5-c5bf50f0e828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [1]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['better', 'sleeping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329be0c5-b948-413a-9a33-e8f6e7a43f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c129e4c1-54f8-4b29-9795-afc27b0ed703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3\n",
      "Tokenized sequences: [[1], [2]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the text containing the words\n",
    "texts = [\"sleeping\", \"sleep\"]\n",
    "\n",
    "# Initialize Tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "# Fit tokenizer on texts\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Tokenize the texts\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# Check vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary size:\", vocab_size)\n",
    "\n",
    "# Print the tokenized sequences\n",
    "print(\"Tokenized sequences:\", sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5405d7b3-f8bf-4bd3-9c8c-da5a8a869cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4263b7fc-8ada-43e2-93ca-6d5864bf8dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1355e-1549-4a3d-957e-95f859ec0016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9251ed5b-9fd4-46c4-b0fb-60b590e9ba64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bccd34-098c-44f5-8bd6-0ed0def05577",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Define the LSTM model architecture\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m----> 6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mEmbedding(vocab_size, \u001b[43membedding_size\u001b[49m))\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTM(lstm_units))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ... (additional layers)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_size' is not defined"
     ]
    }
   ],
   "source": [
    "# using LSTM\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, embedding_size))\n",
    "model.add(keras.layers.LSTM(lstm_units))\n",
    "# ... (additional layers)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train the model on historical user search data\n",
    "model.fit(user_search_sequences, target_sequences, epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d49f420-a055-46fe-906a-e73423ee1b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_KEY =\"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae8c0e70-d0b1-4ce1-b978-718ebddb8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12208df6-4570-4bd9-a310-7f6cb32f263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data of user search history and liked keywords\n",
    "user_search_history = [\n",
    "    \"deep learning\", \"neural networks\", \"natural language processing\", \"image recognition\",\n",
    "    \"machine learning\", \"text classification\", \"sentiment analysis\", \"data visualization\"\n",
    "]\n",
    "liked_keywords = [\"neural networks\", \"natural language processing\", \"text classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1fb934c8-de50-428d-ac4e-d9757c23999b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep',\n",
       " 'learning',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'image',\n",
       " 'recognition',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'text',\n",
       " 'classification',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'data',\n",
       " 'visualization']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize user search history and create a vocabulary\n",
    "tokenized_history = [token.text.lower() for query in user_search_history for token in nlp(query)]\n",
    "vocab = Counter(tokenized_history)\n",
    "tokenized_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab3e58c7-8523-47ea-9480-e38f69bc7f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract keywords from user input\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    keywords = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63ea77d4-6a96-4fe9-bd63-58968ede5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map words to indices for encoding\n",
    "word_to_index = {word: index for index, (word, _) in enumerate(vocab.items())}\n",
    "index_to_word = {index: word for word, index in word_to_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c11d9f42-2248-4458-ab30-7617093e12d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deep': 0, 'learning': 1, 'neural': 2, 'networks': 3, 'natural': 4, 'language': 5, 'processing': 6, 'image': 7, 'recognition': 8, 'machine': 9, 'text': 10, 'classification': 11, 'sentiment': 12, 'analysis': 13, 'data': 14, 'visualization': 15}\n",
      "{0: 'deep', 1: 'learning', 2: 'neural', 3: 'networks', 4: 'natural', 5: 'language', 6: 'processing', 7: 'image', 8: 'recognition', 9: 'machine', 10: 'text', 11: 'classification', 12: 'sentiment', 13: 'analysis', 14: 'data', 15: 'visualization'}\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index)\n",
    "print(index_to_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f769de97-5ba6-4a58-b011-f88b5effe698",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Embedding: {'input_length': 1000}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m index_to_word \u001b[38;5;241m=\u001b[39m {index: word \u001b[38;5;28;01mfor\u001b[39;00m word, index \u001b[38;5;129;01min\u001b[39;00m word_to_index\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define the neural network model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      8\u001b[0m     layers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[1;32m      9\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     10\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m ])\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/personal/major project/backend/env/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:81\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, embeddings_constraint, mask_zero, lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     72\u001b[0m     input_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     80\u001b[0m ):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim \u001b[38;5;241m=\u001b[39m input_dim\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim \u001b[38;5;241m=\u001b[39m output_dim\n",
      "File \u001b[0;32m~/Projects/personal/major project/backend/env/lib/python3.12/site-packages/keras/src/layers/layer.py:265\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_policy \u001b[38;5;241m=\u001b[39m dtype_policies\u001b[38;5;241m.\u001b[39mget(dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Embedding: {'input_length': 1000}"
     ]
    }
   ],
   "source": [
    "\n",
    "# Map words to indices for encoding\n",
    "word_to_index = {word: index for index, (word, _) in enumerate(vocab.items())}\n",
    "index_to_word = {index: word for word, index in word_to_index.items()}\n",
    "\n",
    "# Define the neural network model\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=len(vocab), output_dim=128, input_length = 1000),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "# Now you can use this trained model to prioritize user search results based on previously liked keywords.\n",
    "# Given a new search query, tokenize it, convert to indices, and pass it through the model to get the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6acb45ab-fc19-47a5-a125-4d500dcd5c91",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Prepare data for training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword_to_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muser_search_history\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(word \u001b[38;5;129;01min\u001b[39;00m liked_keywords \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m nlp(query)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m user_search_history])\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "X = np.array([[word_to_index[token.text.lower()] for token in nlp(query)] for query in user_search_history])\n",
    "y = np.array([1 if any(word in liked_keywords for word in nlp(query)) else 0 for query in user_search_history])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b968bfef-7634-4927-a0ca-1afa46ef6ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.05279589  0.43462123  0.56446557 ... -0.21558542 -0.48716266\n",
      "  -0.32593815]\n",
      " [-0.18021194  0.88805299  0.10379477 ...  0.54008547 -0.65012576\n",
      "  -0.77059586]\n",
      " ...\n",
      " [-0.14913941  0.18610728 -0.70102764 ... -0.96837596  0.344502\n",
      "   0.22158446]\n",
      " [ 0.60155447 -0.26443112 -0.05675138 ...  0.68479661 -0.41752299\n",
      "   0.18084771]\n",
      " [-0.06753045 -0.92260275  0.30947412 ...  0.33175464 -0.66563538\n",
      "   0.5770741 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Sample text input\n",
    "text_input = [\n",
    "    \"This is an example sentence.\",\n",
    "    \"Another example sentence with more words.\",\n",
    "    \"Yet another sentence to demonstrate word embeddings.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5ad97bc-da5f-4e79-8d80-7a5e0d5962cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 1, 'example': 2, 'another': 3, 'this': 4, 'is': 5, 'an': 6, 'with': 7, 'more': 8, 'words': 9, 'yet': 10, 'to': 11, 'demonstrate': 12, 'word': 13, 'embeddings': 14}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize the text input\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_input)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "dir(tokenizer)\n",
    "print(tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79a42b4a-198d-41bb-9166-a86b2f559157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert text to sequences and pad sequences to a fixed length\n",
    "sequences = tokenizer.texts_to_sequences(text_input)\n",
    "max_length = max(len(sequence) for sequence in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97781187-1d74-45d2-a882-fa3b5ab6c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create word embedding matrix\n",
    "embedding_dim = 100  # You can adjust this dimension as needed\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = np.random.uniform(-1, 1, embedding_dim)  # Random initialization\n",
    "    embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "177f9dad-ef9b-4656-816b-2f1f2566e6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.64894336 -0.96631378 -0.51312237 ... -0.10282251 -0.6012645\n",
      "  -0.33397218]\n",
      " [-0.71462387 -0.45171066  0.6505204  ... -0.51602674 -0.56520368\n",
      "   0.35719344]\n",
      " ...\n",
      " [ 0.17553115 -0.79921191 -0.85921446 ... -0.83543187  0.2561677\n",
      "   0.58636922]\n",
      " [-0.11079464 -0.66227062 -0.93281072 ...  0.5700236   0.79761942\n",
      "  -0.9838077 ]\n",
      " [ 0.01833037 -0.94100712 -0.97003552 ... -0.23840626  0.17142113\n",
      "  -0.79295537]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print word embedding array\n",
    "print(embedding_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025c178-de06-40ce-89bd-dab461d63bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
