{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275c4dfb-c91e-454a-8cad-02df1d3048ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "\n",
    "# !pip install tensorflow scikit-learn pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1050c2a3-9345-4a07-8d95-68e21bd7d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection                  import train_test_split\n",
    "# from tensorflow.keras.preprocessing.text      import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence  import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a99c5bdb-ee17-4f78-b637-cce0a7b08c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer as BaseTokenizer\n",
    "\n",
    "class Tokenizer(BaseTokenizer):\n",
    "    def __init__(self, num_words=None, oov_token=None, **kwargs):\n",
    "        super().__init__(num_words=num_words, oov_token=oov_token, **kwargs)\n",
    "        self.next_index = 1  # Initialize the index for unseen words\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            sequence = []\n",
    "            for word in text.split():\n",
    "                index = self.word_index.get(word)\n",
    "                # print(self.word_index)\n",
    "                if index is None:\n",
    "                    index = self.document_count\n",
    "                    self.word_index[word] = index\n",
    "                    self.index_word[index] = word\n",
    "                    self.document_count += 1\n",
    "                    # print(self.index_word)\n",
    "                sequence.append(index)\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b924ad6-2922-445f-a8be-001a7777abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "\n",
    "records = 2000\n",
    "params  = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e99c1322-d1fc-40bc-b736-440d03323a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>meta_data</th>\n",
       "      <th>liked_keywords</th>\n",
       "      <th>priority_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artificial intelligence</td>\n",
       "      <td>Simulation of human intelligence processes by ...</td>\n",
       "      <td>technology future</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quantum mechanics</td>\n",
       "      <td>Description of nature at the smallest scales o...</td>\n",
       "      <td>physics quantum</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Renewable energy</td>\n",
       "      <td>Collection of energy from renewable resources.</td>\n",
       "      <td>environment sustainability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine learning</td>\n",
       "      <td>Development of algorithms and models for compu...</td>\n",
       "      <td>data algorithm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World War II</td>\n",
       "      <td>Global war involving many countries from 1939 ...</td>\n",
       "      <td>history military</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>Best podcasts for learning</td>\n",
       "      <td>Search for information about the best podcasts...</td>\n",
       "      <td>learning podcasts best</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Beginner crochet patterns</td>\n",
       "      <td>Search for beginner-friendly crochet patterns,...</td>\n",
       "      <td>crochet patterns beginner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>DIY natural hair care recipes</td>\n",
       "      <td>Search for do-it-yourself (DIY) natural hair c...</td>\n",
       "      <td>DIY hair care</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Famous contemporary artists</td>\n",
       "      <td>Search for information about famous contempora...</td>\n",
       "      <td>contemporary artists famous</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Indoor herb garden ideas</td>\n",
       "      <td>Search for ideas for creating an indoor herb g...</td>\n",
       "      <td>indoor herb garden ideas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             query  \\\n",
       "0          Artificial intelligence   \n",
       "1                Quantum mechanics   \n",
       "2                 Renewable energy   \n",
       "3                 Machine learning   \n",
       "4                     World War II   \n",
       "..                             ...   \n",
       "520     Best podcasts for learning   \n",
       "521      Beginner crochet patterns   \n",
       "522  DIY natural hair care recipes   \n",
       "523    Famous contemporary artists   \n",
       "524       Indoor herb garden ideas   \n",
       "\n",
       "                                             meta_data  \\\n",
       "0    Simulation of human intelligence processes by ...   \n",
       "1    Description of nature at the smallest scales o...   \n",
       "2       Collection of energy from renewable resources.   \n",
       "3    Development of algorithms and models for compu...   \n",
       "4    Global war involving many countries from 1939 ...   \n",
       "..                                                 ...   \n",
       "520  Search for information about the best podcasts...   \n",
       "521  Search for beginner-friendly crochet patterns,...   \n",
       "522  Search for do-it-yourself (DIY) natural hair c...   \n",
       "523  Search for information about famous contempora...   \n",
       "524  Search for ideas for creating an indoor herb g...   \n",
       "\n",
       "                  liked_keywords  priority_score  \n",
       "0              technology future               1  \n",
       "1                physics quantum               0  \n",
       "2     environment sustainability               1  \n",
       "3                 data algorithm               1  \n",
       "4               history military               0  \n",
       "..                           ...             ...  \n",
       "520       learning podcasts best               1  \n",
       "521    crochet patterns beginner               1  \n",
       "522                DIY hair care               1  \n",
       "523  contemporary artists famous               0  \n",
       "524     indoor herb garden ideas               1  \n",
       "\n",
       "[525 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('dataset/Meta -2.csv')\n",
    "\n",
    "def func(x):\n",
    "    return ' '.join(\n",
    "        x[2:-2].split(\"', '\")\n",
    "    )\n",
    "data['liked_keywords'] = data['liked_keywords'].apply(func)\n",
    "data['priority_score'] /= 100\n",
    "\n",
    "data['priority_score'] = data['priority_score'].apply(lambda x: 1 if x > 0.7 else 0)\n",
    "data\n",
    "# print(help(data['priority_score'].apply))\n",
    "# data['priority_score'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f6daec2-d208-433b-baa0-a9ea664ce28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525, 1000) (525, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# data = pd.read_csv('dataset/Meta -2.csv')\n",
    "\n",
    "data = data[:records]\n",
    "\n",
    "# print(tokenizer, dir(tokenizer))\n",
    "# Assuming `data` is a DataFrame with columns 'query', 'likes', and 'priority_percentage'\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=None)\n",
    "tokenizer.fit_on_texts(data['query'] + ' ' + data['liked_keywords'])\n",
    "\n",
    "# Convert text to sequences\n",
    "query_sequences = tokenizer.texts_to_sequences(data['query'])\n",
    "likes_sequences = tokenizer.texts_to_sequences(data['liked_keywords'])\n",
    "\n",
    "# Pad sequences\n",
    "query_padded = pad_sequences(query_sequences, padding='post', maxlen = params)\n",
    "likes_padded = pad_sequences(likes_sequences, padding='post', maxlen = params)\n",
    "\n",
    "\n",
    "print(query_padded.shape, likes_padded.shape)\n",
    "# print(data[['query', 'liked_keywords', 'priority_score']], query_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a31d4cb0-8965-4940-aafd-65dc42941391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_sequences\n",
    "# data['query'][0]\n",
    "# tokenizer.texts_to_sequences([data['query'][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eeab91d4-5773-4c86-b032-17c39dcd9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Concatenate, SimpleRNN, Dense\n",
    "\n",
    "# # Define the model architecture\n",
    "# query_input = Input(shape=(params,), dtype='int32')\n",
    "# likes_input = Input(shape=(params,), dtype='int32')\n",
    "\n",
    "# # Embedding layers for both inputs\n",
    "# query_embedding = Embedding(input_dim=params, output_dim=128)(query_input)\n",
    "# likes_embedding = Embedding(input_dim=params, output_dim=128)(likes_input)\n",
    "\n",
    "# # Concatenate the embeddings\n",
    "# merged = Concatenate()([query_embedding, likes_embedding])\n",
    "# # \n",
    "# # Simple RNN layer\n",
    "# rnn_layer = Dense(128)(merged)\n",
    "\n",
    "# # Dense layer for regression\n",
    "# output = Dense(1)(rnn_layer)\n",
    "\n",
    "# # Compile the model\n",
    "# model = Model(inputs=[query_input, likes_input], outputs=output)\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=['accuracy', 'precision', 'recall', 'f1_score'])\n",
    "# print(query_padded.shape, likes_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8f21662-7b6a-4862-854d-0576ef87a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layers for website metadata and user past liked keywords\n",
    "website_metadata_input = Input(shape=(params,))\n",
    "user_liked_keywords_input = Input(shape=(params,))\n",
    "\n",
    "# Concatenate the inputs\n",
    "concatenated_inputs = Concatenate()([website_metadata_input, user_liked_keywords_input])\n",
    "\n",
    "# Dense layers\n",
    "dense1 = Dense(512, activation='relu')(concatenated_inputs)\n",
    "dense2 = Dense(256, activation='relu')(dense1)\n",
    "output = Dense(1, activation='sigmoid')(dense2)  # Output layer with sigmoid activation for binary classification\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[website_metadata_input, user_liked_keywords_input], outputs=output)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "560e4a4d-701c-4ddc-9fb2-7e6f9cd24ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024,512</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m1,024,512\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,156,097</span> (4.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,156,097\u001b[0m (4.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,156,097</span> (4.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,156,097\u001b[0m (4.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir(model)\n",
    "model.summary()\n",
    "# help(model.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60630994-da06-4bb5-b793-7c2787218ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6518 - loss: 13.1121 \n",
      "Epoch 2/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7966 - loss: 3.6130\n",
      "Epoch 3/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.8053\n",
      "Epoch 4/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7706 - loss: 0.8162\n",
      "Epoch 5/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7798 - loss: 0.7079\n",
      "Epoch 6/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.4628\n",
      "Epoch 7/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8103 - loss: 0.5137\n",
      "Epoch 8/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8418 - loss: 0.4806\n",
      "Epoch 9/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 0.4605\n",
      "Epoch 10/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8172 - loss: 0.6041\n",
      "Epoch 11/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8340 - loss: 0.6009\n",
      "Epoch 12/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.7750\n",
      "Epoch 13/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7919 - loss: 0.7269\n",
      "Epoch 14/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 0.3822\n",
      "Epoch 15/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8353 - loss: 0.4673\n",
      "Epoch 16/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8661 - loss: 0.3961\n",
      "Epoch 17/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8494 - loss: 0.3825\n",
      "Epoch 18/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.4365\n",
      "Epoch 19/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.5169\n",
      "Epoch 20/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.4863\n",
      "Epoch 21/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8421 - loss: 0.4601\n",
      "Epoch 22/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8479 - loss: 0.3936\n",
      "Epoch 23/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8491 - loss: 0.3643\n",
      "Epoch 24/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.3207\n",
      "Epoch 25/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8464 - loss: 0.4029\n",
      "Epoch 26/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8753 - loss: 0.3099\n",
      "Epoch 27/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8656 - loss: 0.3697\n",
      "Epoch 28/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7745 - loss: 0.5579\n",
      "Epoch 29/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8418 - loss: 0.3972\n",
      "Epoch 30/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8402 - loss: 0.4541\n",
      "Epoch 31/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8310 - loss: 0.3756\n",
      "Epoch 32/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8939 - loss: 0.3126\n",
      "Epoch 33/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8525 - loss: 0.3874\n",
      "Epoch 34/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8781 - loss: 0.3270\n",
      "Epoch 35/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.3193\n",
      "Epoch 36/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8630 - loss: 0.3115\n",
      "Epoch 37/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8685 - loss: 0.3892\n",
      "Epoch 38/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 0.3808\n",
      "Epoch 39/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8587 - loss: 0.3450\n",
      "Epoch 40/40\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.3560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x364254f50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "model.fit([query_padded, likes_padded], data['priority_score'], epochs=40, batch_size=32)\n",
    "# print(model.metrics_names)\n",
    "# model.evaluate([query_padded, likes_padded], data['priority_score'], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7cc17ca0-fac8-4109-b68b-b8ec4ac8840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# saving tokenizer\n",
    "with open(\"../models/tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, handle)\n",
    "\n",
    "# # loading\n",
    "# with open('../models/tokenizer.pickle', 'rb') as handle:\n",
    "#     tokenizer1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9272cc4-a173-446c-80ca-70ada1e4747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[822, 305, 83, 823, 824, 825]]\n",
      "822 helllooooo\n",
      "305 interaction\n",
      "83 a\n",
      "823 b\n",
      "824 c\n",
      "825 d\n"
     ]
    }
   ],
   "source": [
    "res = tokenizer1.texts_to_sequences(['helllooooo interaction a b c d'])\n",
    "print(res)\n",
    "for i in res[0]:\n",
    "    print(i, tokenizer1.index_word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5d1c7b9-2c49-4f40-a03c-b28c0ac5bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.99044704e-01],\n",
       "       [6.52937949e-01],\n",
       "       [7.04397678e-01],\n",
       "       [8.31732810e-01],\n",
       "       [2.68196374e-01],\n",
       "       [9.61292326e-01],\n",
       "       [8.60777259e-01],\n",
       "       [6.79740369e-01],\n",
       "       [9.88811731e-01],\n",
       "       [5.82066238e-01],\n",
       "       [9.37829256e-01],\n",
       "       [8.54364872e-01],\n",
       "       [9.73038256e-01],\n",
       "       [8.50167990e-01],\n",
       "       [6.41321182e-01],\n",
       "       [5.81077695e-01],\n",
       "       [8.83109808e-01],\n",
       "       [8.53594899e-01],\n",
       "       [9.79163349e-01],\n",
       "       [6.83489919e-01],\n",
       "       [8.97073984e-01],\n",
       "       [9.70971882e-01],\n",
       "       [5.70396602e-01],\n",
       "       [9.45311308e-01],\n",
       "       [8.70199621e-01],\n",
       "       [7.28792489e-01],\n",
       "       [9.79288280e-01],\n",
       "       [6.73702180e-01],\n",
       "       [9.50828195e-01],\n",
       "       [9.80070591e-01],\n",
       "       [9.63394582e-01],\n",
       "       [9.67164457e-01],\n",
       "       [7.28836894e-01],\n",
       "       [9.70570028e-01],\n",
       "       [5.64430594e-01],\n",
       "       [9.71497238e-01],\n",
       "       [9.88919318e-01],\n",
       "       [9.73116875e-01],\n",
       "       [9.73701477e-01],\n",
       "       [9.90481019e-01],\n",
       "       [9.79723871e-01],\n",
       "       [8.78542662e-01],\n",
       "       [8.15646052e-01],\n",
       "       [9.05601442e-01],\n",
       "       [8.37016106e-01],\n",
       "       [9.53507066e-01],\n",
       "       [9.76096213e-01],\n",
       "       [9.49003994e-01],\n",
       "       [8.21001112e-01],\n",
       "       [4.27132517e-01],\n",
       "       [8.90428066e-01],\n",
       "       [8.57882082e-01],\n",
       "       [9.82628107e-01],\n",
       "       [5.85826159e-01],\n",
       "       [9.79159594e-01],\n",
       "       [1.94928467e-01],\n",
       "       [9.99359488e-01],\n",
       "       [9.92760956e-01],\n",
       "       [9.90295351e-01],\n",
       "       [7.89204776e-01],\n",
       "       [3.58242869e-01],\n",
       "       [7.09690750e-01],\n",
       "       [7.79497802e-01],\n",
       "       [6.29040599e-01],\n",
       "       [9.71423984e-01],\n",
       "       [9.98970866e-01],\n",
       "       [9.70465302e-01],\n",
       "       [9.48941767e-01],\n",
       "       [9.98691022e-01],\n",
       "       [6.99931681e-02],\n",
       "       [9.50146377e-01],\n",
       "       [9.33090627e-01],\n",
       "       [8.80549073e-01],\n",
       "       [7.69149721e-01],\n",
       "       [9.88441348e-01],\n",
       "       [8.32783997e-01],\n",
       "       [9.89515901e-01],\n",
       "       [9.99114871e-01],\n",
       "       [9.23956871e-01],\n",
       "       [1.83806211e-01],\n",
       "       [9.57021654e-01],\n",
       "       [7.73664832e-01],\n",
       "       [9.56313431e-01],\n",
       "       [9.84306037e-01],\n",
       "       [7.13645697e-01],\n",
       "       [9.12272334e-01],\n",
       "       [9.87640083e-01],\n",
       "       [8.36119771e-01],\n",
       "       [6.27202749e-01],\n",
       "       [8.19764674e-01],\n",
       "       [9.72423851e-01],\n",
       "       [8.62418890e-01],\n",
       "       [9.25089419e-01],\n",
       "       [8.87992799e-01],\n",
       "       [9.51200902e-01],\n",
       "       [8.83010149e-01],\n",
       "       [9.73021746e-01],\n",
       "       [8.79071355e-01],\n",
       "       [9.19433653e-01],\n",
       "       [8.75593245e-01],\n",
       "       [8.30031931e-01],\n",
       "       [7.17440188e-01],\n",
       "       [5.79791665e-01],\n",
       "       [7.10769534e-01],\n",
       "       [9.23088372e-01],\n",
       "       [9.14600551e-01],\n",
       "       [9.42609727e-01],\n",
       "       [9.12278891e-01],\n",
       "       [9.14729118e-01],\n",
       "       [9.76798952e-01],\n",
       "       [9.38949466e-01],\n",
       "       [8.45597148e-01],\n",
       "       [7.58599818e-01],\n",
       "       [9.41590741e-02],\n",
       "       [9.99385774e-01],\n",
       "       [9.74023044e-01],\n",
       "       [9.67058480e-01],\n",
       "       [7.96466112e-01],\n",
       "       [9.67655420e-01],\n",
       "       [9.75414872e-01],\n",
       "       [9.95330513e-01],\n",
       "       [1.81582617e-03],\n",
       "       [9.99994814e-01],\n",
       "       [9.77367282e-01],\n",
       "       [9.76809740e-01],\n",
       "       [9.99999046e-01],\n",
       "       [9.99997377e-01],\n",
       "       [2.78387696e-01],\n",
       "       [9.78487015e-01],\n",
       "       [9.99998987e-01],\n",
       "       [9.93787229e-01],\n",
       "       [9.81791735e-01],\n",
       "       [9.81373310e-01],\n",
       "       [8.41182113e-01],\n",
       "       [9.99999762e-01],\n",
       "       [9.80289698e-01],\n",
       "       [9.93226230e-01],\n",
       "       [9.99904096e-01],\n",
       "       [9.99997497e-01],\n",
       "       [9.71299708e-02],\n",
       "       [9.85778153e-01],\n",
       "       [9.99861002e-01],\n",
       "       [9.41590741e-02],\n",
       "       [9.99385774e-01],\n",
       "       [9.74023044e-01],\n",
       "       [9.67058480e-01],\n",
       "       [7.96466112e-01],\n",
       "       [5.72090805e-01],\n",
       "       [9.99859810e-01],\n",
       "       [9.37972665e-01],\n",
       "       [9.88242388e-01],\n",
       "       [9.81689394e-01],\n",
       "       [9.99999821e-01],\n",
       "       [9.95095611e-01],\n",
       "       [9.88312244e-01],\n",
       "       [2.47766059e-02],\n",
       "       [9.99885440e-01],\n",
       "       [9.80522752e-01],\n",
       "       [9.90566313e-01],\n",
       "       [9.99402702e-01],\n",
       "       [9.99999344e-01],\n",
       "       [2.80341148e-01],\n",
       "       [9.90289092e-01],\n",
       "       [8.47040772e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.96825516e-01],\n",
       "       [9.99087214e-01],\n",
       "       [9.46073269e-04],\n",
       "       [7.52109289e-01],\n",
       "       [9.86006856e-01],\n",
       "       [9.91823554e-01],\n",
       "       [8.26944470e-01],\n",
       "       [9.99999583e-01],\n",
       "       [7.80295968e-01],\n",
       "       [9.92945552e-01],\n",
       "       [9.90375161e-01],\n",
       "       [4.82336879e-01],\n",
       "       [4.63778496e-01],\n",
       "       [1.76793247e-01],\n",
       "       [8.82372022e-01],\n",
       "       [7.82009661e-01],\n",
       "       [9.81835783e-01],\n",
       "       [7.47575521e-01],\n",
       "       [7.99218535e-01],\n",
       "       [6.58511162e-01],\n",
       "       [8.10996532e-01],\n",
       "       [9.99999940e-01],\n",
       "       [8.78109634e-01],\n",
       "       [7.73754120e-01],\n",
       "       [9.99983728e-01],\n",
       "       [7.43269563e-01],\n",
       "       [9.95684862e-01],\n",
       "       [9.55663085e-01],\n",
       "       [9.55526769e-01],\n",
       "       [9.99999464e-01],\n",
       "       [9.35977757e-01],\n",
       "       [7.84006059e-01],\n",
       "       [9.24013615e-01],\n",
       "       [9.88316000e-01],\n",
       "       [9.90986943e-01],\n",
       "       [9.94457603e-01],\n",
       "       [7.85092413e-01],\n",
       "       [4.18757617e-01],\n",
       "       [7.87028611e-01],\n",
       "       [7.33820736e-01],\n",
       "       [6.71778142e-01],\n",
       "       [7.55237937e-01],\n",
       "       [9.91717577e-01],\n",
       "       [9.91737068e-01],\n",
       "       [8.94357204e-01],\n",
       "       [9.92894471e-01],\n",
       "       [9.88851249e-01],\n",
       "       [9.95121479e-01],\n",
       "       [9.99553144e-01],\n",
       "       [9.03239823e-04],\n",
       "       [9.99945343e-01],\n",
       "       [9.99998331e-01],\n",
       "       [7.80808747e-01],\n",
       "       [9.85918343e-01],\n",
       "       [9.75667536e-01],\n",
       "       [6.77167118e-01],\n",
       "       [1.00000000e+00],\n",
       "       [8.40002179e-01],\n",
       "       [9.55526769e-01],\n",
       "       [9.99991298e-01],\n",
       "       [9.35977757e-01],\n",
       "       [7.84006059e-01],\n",
       "       [9.24013615e-01],\n",
       "       [9.88316000e-01],\n",
       "       [9.90907311e-01],\n",
       "       [9.94457603e-01],\n",
       "       [7.85092413e-01],\n",
       "       [4.18757617e-01],\n",
       "       [7.87028611e-01],\n",
       "       [7.33820736e-01],\n",
       "       [9.79173720e-01],\n",
       "       [6.99402630e-01],\n",
       "       [9.78870630e-01],\n",
       "       [6.71778142e-01],\n",
       "       [9.01940167e-01],\n",
       "       [9.82077062e-01],\n",
       "       [9.96565461e-01],\n",
       "       [8.07230115e-01],\n",
       "       [9.99998987e-01],\n",
       "       [2.06873436e-02],\n",
       "       [9.99943018e-01],\n",
       "       [9.53497171e-01],\n",
       "       [9.14918840e-01],\n",
       "       [6.55779064e-01],\n",
       "       [9.65220034e-01],\n",
       "       [2.61243153e-03],\n",
       "       [9.98745739e-01],\n",
       "       [9.99367595e-01],\n",
       "       [9.78539467e-01],\n",
       "       [8.98130000e-01],\n",
       "       [9.56599653e-01],\n",
       "       [5.59970915e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.19836044e-01],\n",
       "       [9.17780757e-01],\n",
       "       [9.62446868e-01],\n",
       "       [6.23893738e-01],\n",
       "       [4.67491057e-03],\n",
       "       [9.47092235e-01],\n",
       "       [9.98618722e-01],\n",
       "       [9.86612201e-01],\n",
       "       [9.89970624e-01],\n",
       "       [9.03105855e-01],\n",
       "       [9.63400364e-01],\n",
       "       [8.87392819e-01],\n",
       "       [9.99999881e-01],\n",
       "       [3.86137813e-01],\n",
       "       [7.02054381e-01],\n",
       "       [9.57226932e-01],\n",
       "       [8.14219117e-01],\n",
       "       [9.99656796e-01],\n",
       "       [9.54532146e-01],\n",
       "       [9.97484207e-01],\n",
       "       [9.63520765e-01],\n",
       "       [9.93678510e-01],\n",
       "       [7.16750417e-03],\n",
       "       [9.61577177e-01],\n",
       "       [9.57266271e-01],\n",
       "       [9.36753213e-01],\n",
       "       [9.92668748e-01],\n",
       "       [9.92632151e-01],\n",
       "       [9.99884963e-01],\n",
       "       [9.97552812e-01],\n",
       "       [9.33555603e-01],\n",
       "       [9.79193747e-01],\n",
       "       [9.32322383e-01],\n",
       "       [9.31836724e-01],\n",
       "       [9.79514778e-01],\n",
       "       [9.77232814e-01],\n",
       "       [9.93911147e-01],\n",
       "       [9.25875008e-01],\n",
       "       [9.94358242e-01],\n",
       "       [6.98737562e-01],\n",
       "       [9.70529377e-01],\n",
       "       [9.71441448e-01],\n",
       "       [9.58992660e-01],\n",
       "       [9.98883843e-01],\n",
       "       [8.15801919e-01],\n",
       "       [9.67624307e-01],\n",
       "       [9.36528742e-01],\n",
       "       [9.78623807e-01],\n",
       "       [9.39491868e-01],\n",
       "       [9.76886213e-01],\n",
       "       [9.99244809e-01],\n",
       "       [9.78809357e-01],\n",
       "       [8.15497279e-01],\n",
       "       [9.32712197e-01],\n",
       "       [9.70719337e-01],\n",
       "       [9.71629918e-01],\n",
       "       [9.59274113e-01],\n",
       "       [3.17247352e-03],\n",
       "       [9.66216624e-01],\n",
       "       [9.40935433e-01],\n",
       "       [9.81627524e-01],\n",
       "       [8.14849496e-01],\n",
       "       [9.71251786e-01],\n",
       "       [9.58709300e-01],\n",
       "       [9.98863101e-01],\n",
       "       [9.71095741e-01],\n",
       "       [8.16442668e-01],\n",
       "       [9.53173280e-01],\n",
       "       [9.94153559e-01],\n",
       "       [9.53883708e-01],\n",
       "       [9.73236501e-01],\n",
       "       [8.67090583e-01],\n",
       "       [9.99995172e-01],\n",
       "       [9.57458317e-01],\n",
       "       [8.64657164e-01],\n",
       "       [9.97711599e-01],\n",
       "       [9.87468064e-01],\n",
       "       [1.86319376e-04],\n",
       "       [8.62186551e-01],\n",
       "       [9.88698065e-01],\n",
       "       [9.61398542e-01],\n",
       "       [8.60936999e-01],\n",
       "       [9.99707580e-01],\n",
       "       [1.48342573e-04],\n",
       "       [8.59677851e-01],\n",
       "       [9.99999404e-01],\n",
       "       [9.99997914e-01],\n",
       "       [9.99858797e-01],\n",
       "       [9.99977529e-01],\n",
       "       [8.35457206e-01],\n",
       "       [9.98765111e-01],\n",
       "       [9.13985312e-01],\n",
       "       [8.73010397e-01],\n",
       "       [7.52693653e-01],\n",
       "       [9.99985456e-01],\n",
       "       [2.21428811e-03],\n",
       "       [9.99996603e-01],\n",
       "       [9.97377813e-01],\n",
       "       [9.99492586e-01],\n",
       "       [9.07576442e-01],\n",
       "       [9.97572958e-01],\n",
       "       [3.95610034e-02],\n",
       "       [9.71347153e-01],\n",
       "       [9.99677241e-01],\n",
       "       [7.81797349e-01],\n",
       "       [9.99984145e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.18149650e-01],\n",
       "       [9.69347954e-01],\n",
       "       [9.97283340e-01],\n",
       "       [9.91749942e-01],\n",
       "       [9.70578194e-01],\n",
       "       [9.44077909e-01],\n",
       "       [4.18149650e-01],\n",
       "       [9.69347954e-01],\n",
       "       [9.97283340e-01],\n",
       "       [9.91749942e-01],\n",
       "       [9.70578194e-01],\n",
       "       [9.44077909e-01],\n",
       "       [4.18149650e-01],\n",
       "       [9.69347954e-01],\n",
       "       [9.97283340e-01],\n",
       "       [9.91749942e-01],\n",
       "       [9.70578194e-01],\n",
       "       [9.44077909e-01],\n",
       "       [7.01638818e-01],\n",
       "       [9.01449502e-01],\n",
       "       [7.04196811e-01],\n",
       "       [7.05046892e-01],\n",
       "       [9.03047323e-01],\n",
       "       [7.06742883e-01],\n",
       "       [7.07587838e-01],\n",
       "       [9.04622078e-01],\n",
       "       [7.09274530e-01],\n",
       "       [9.05659318e-01],\n",
       "       [7.10954249e-01],\n",
       "       [9.06684399e-01],\n",
       "       [7.12630689e-01],\n",
       "       [9.07662928e-01],\n",
       "       [5.52967250e-01],\n",
       "       [9.08158422e-01],\n",
       "       [9.98777866e-01],\n",
       "       [9.96243596e-01],\n",
       "       [9.98900592e-01],\n",
       "       [9.99433756e-01],\n",
       "       [4.94998008e-01],\n",
       "       [9.96487141e-01],\n",
       "       [9.98800933e-01],\n",
       "       [9.96384740e-01],\n",
       "       [9.98948097e-01],\n",
       "       [9.99387085e-01],\n",
       "       [5.00448823e-01],\n",
       "       [5.77496469e-01],\n",
       "       [9.99985576e-01],\n",
       "       [9.96083260e-01],\n",
       "       [5.79599917e-01],\n",
       "       [9.97200727e-01],\n",
       "       [4.61411715e-01],\n",
       "       [6.77311540e-01],\n",
       "       [9.95863259e-01],\n",
       "       [9.99973774e-01],\n",
       "       [5.78013599e-01],\n",
       "       [4.60453421e-01],\n",
       "       [5.77791154e-01],\n",
       "       [9.99985516e-01],\n",
       "       [9.96032238e-01],\n",
       "       [9.99985516e-01],\n",
       "       [9.99974191e-01],\n",
       "       [5.01569629e-01],\n",
       "       [6.88289225e-01],\n",
       "       [9.99985218e-01],\n",
       "       [7.14016438e-01],\n",
       "       [4.95646238e-01],\n",
       "       [9.99973655e-01],\n",
       "       [9.99985337e-01],\n",
       "       [4.33759280e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.99560475e-01],\n",
       "       [9.74186718e-01],\n",
       "       [9.90711629e-01],\n",
       "       [9.99862134e-01],\n",
       "       [9.68158424e-01],\n",
       "       [9.88805234e-01],\n",
       "       [9.23446059e-01],\n",
       "       [8.99501681e-01],\n",
       "       [9.94387448e-01],\n",
       "       [9.99570012e-01],\n",
       "       [9.88574088e-01],\n",
       "       [9.94558632e-01],\n",
       "       [1.36739705e-02],\n",
       "       [9.96586382e-01],\n",
       "       [9.99894738e-01],\n",
       "       [9.99995947e-01],\n",
       "       [9.93534744e-01],\n",
       "       [9.99971032e-01],\n",
       "       [1.37525185e-05],\n",
       "       [9.92553949e-01],\n",
       "       [9.92233992e-01],\n",
       "       [9.72647309e-01],\n",
       "       [9.19653654e-01],\n",
       "       [9.92618740e-01],\n",
       "       [7.21755147e-01],\n",
       "       [9.96822894e-01],\n",
       "       [9.85442281e-01],\n",
       "       [9.90818918e-01],\n",
       "       [9.98889863e-01],\n",
       "       [7.26270258e-01],\n",
       "       [5.64761162e-01],\n",
       "       [9.99999642e-01],\n",
       "       [9.60746765e-01],\n",
       "       [9.92687285e-01],\n",
       "       [9.73869085e-01],\n",
       "       [9.99889374e-01],\n",
       "       [1.75949628e-03],\n",
       "       [9.90558267e-01],\n",
       "       [9.97037649e-01],\n",
       "       [9.06378090e-01],\n",
       "       [6.76875532e-01],\n",
       "       [9.96944726e-01],\n",
       "       [6.73763752e-01],\n",
       "       [8.93983960e-01],\n",
       "       [4.33759280e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.99560475e-01],\n",
       "       [9.74186718e-01],\n",
       "       [9.90711629e-01],\n",
       "       [9.99862134e-01],\n",
       "       [9.68158424e-01],\n",
       "       [9.88805234e-01],\n",
       "       [9.23446059e-01],\n",
       "       [8.99501681e-01],\n",
       "       [9.94387448e-01],\n",
       "       [9.99570012e-01],\n",
       "       [9.88574088e-01],\n",
       "       [9.94558632e-01],\n",
       "       [1.36739705e-02],\n",
       "       [9.96586382e-01],\n",
       "       [9.99894738e-01],\n",
       "       [9.99995947e-01],\n",
       "       [9.93534744e-01],\n",
       "       [9.99971032e-01],\n",
       "       [1.37525185e-05],\n",
       "       [9.92553949e-01],\n",
       "       [9.92233992e-01],\n",
       "       [9.72647309e-01],\n",
       "       [9.19653654e-01],\n",
       "       [9.92618740e-01],\n",
       "       [7.21755147e-01],\n",
       "       [9.96822894e-01],\n",
       "       [9.85442281e-01],\n",
       "       [9.90818918e-01],\n",
       "       [9.98889863e-01],\n",
       "       [7.26270258e-01],\n",
       "       [5.64761162e-01],\n",
       "       [9.99999642e-01],\n",
       "       [9.60746765e-01],\n",
       "       [9.92687285e-01],\n",
       "       [9.73869085e-01],\n",
       "       [9.99889374e-01],\n",
       "       [1.75949628e-03],\n",
       "       [9.90558267e-01],\n",
       "       [9.97037649e-01],\n",
       "       [9.06378090e-01],\n",
       "       [6.76875532e-01],\n",
       "       [9.96944726e-01],\n",
       "       [6.73763752e-01],\n",
       "       [8.93983960e-01]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([query_padded, likes_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "249d777f-2aca-453d-b668-22d2ac2a40b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8630 - loss: 0.2827 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24521112442016602, 0.8876190185546875]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([query_padded, likes_padded], data['priority_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef5c4b94-a5d8-49ff-a83e-88768017ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hello.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dae7f438-17f6-4140-8892-9c439cecf0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'of': 1,\n",
       " 'history': 2,\n",
       " 'indian': 3,\n",
       " 'tips': 4,\n",
       " 'for': 5,\n",
       " 'games': 6,\n",
       " 'disney': 7,\n",
       " 'kids': 8,\n",
       " 'goddess': 9,\n",
       " 'tv': 10,\n",
       " 'diy': 11,\n",
       " 'movies': 12,\n",
       " 'hinduism': 13,\n",
       " 'lord': 14,\n",
       " 'recipes': 15,\n",
       " 'hindu': 16,\n",
       " 'travel': 17,\n",
       " 'symptoms': 18,\n",
       " 'treatment': 19,\n",
       " 'famous': 20,\n",
       " 'music': 21,\n",
       " 'india': 22,\n",
       " 'video': 23,\n",
       " 'to': 24,\n",
       " 'shows': 25,\n",
       " 'beginner': 26,\n",
       " 'science': 27,\n",
       " 'how': 28,\n",
       " 'influence': 29,\n",
       " 'best': 30,\n",
       " 'the': 31,\n",
       " 'home': 32,\n",
       " 'lego': 33,\n",
       " 'learning': 34,\n",
       " 'animals': 35,\n",
       " 'building': 36,\n",
       " 'causes': 37,\n",
       " 'empire': 38,\n",
       " 'series': 39,\n",
       " 'toys': 40,\n",
       " 'ideas': 41,\n",
       " 'ancient': 42,\n",
       " 'temples': 43,\n",
       " 'shiva': 44,\n",
       " 'krishna': 45,\n",
       " 'indoor': 46,\n",
       " 'easy': 47,\n",
       " 'in': 48,\n",
       " 'songs': 49,\n",
       " 'quantum': 50,\n",
       " 'education': 51,\n",
       " 'singer': 52,\n",
       " 'animal': 53,\n",
       " 'stories': 54,\n",
       " 'puja': 55,\n",
       " 'biology': 56,\n",
       " 'culture': 57,\n",
       " 'art': 58,\n",
       " 'cartoons': 59,\n",
       " 'videos': 60,\n",
       " 'sets': 61,\n",
       " 'chemistry': 62,\n",
       " 'health': 63,\n",
       " 'engineering': 64,\n",
       " 'philosophy': 65,\n",
       " 'books': 66,\n",
       " 'mathematics': 67,\n",
       " 'geography': 68,\n",
       " 'prevention': 69,\n",
       " 'coloring': 70,\n",
       " 'yoga': 71,\n",
       " 'dance': 72,\n",
       " 'diabetes': 73,\n",
       " 'arthritis': 74,\n",
       " 'textiles': 75,\n",
       " 'god': 76,\n",
       " 'lakshmi': 77,\n",
       " 'vishnu': 78,\n",
       " 'kali': 79,\n",
       " 'radha': 80,\n",
       " 'sita': 81,\n",
       " 'mantra': 82,\n",
       " 'a': 83,\n",
       " 'hiking': 84,\n",
       " 'trails': 85,\n",
       " 'decor': 86,\n",
       " 'organizing': 87,\n",
       " 'natural': 88,\n",
       " 'impressionist': 89,\n",
       " 'painters': 90,\n",
       " 'homemade': 91,\n",
       " 'destinations': 92,\n",
       " 'garden': 93,\n",
       " 'classic': 94,\n",
       " 'patterns': 95,\n",
       " 'artists': 96,\n",
       " 'care': 97,\n",
       " 'economics': 98,\n",
       " 'europe': 99,\n",
       " 'and': 100,\n",
       " 'artifacts': 101,\n",
       " 'architecture': 102,\n",
       " 'facts': 103,\n",
       " 'characters': 104,\n",
       " 'activities': 105,\n",
       " 'hypertension': 106,\n",
       " 'prevent': 107,\n",
       " 'technology': 108,\n",
       " 'physics': 109,\n",
       " 'environment': 110,\n",
       " 'psychology': 111,\n",
       " 'society': 112,\n",
       " 'theory': 113,\n",
       " 'magic': 114,\n",
       " 'tricks': 115,\n",
       " 'experiments': 116,\n",
       " 'cooking': 117,\n",
       " 'online': 118,\n",
       " 'classes': 119,\n",
       " 'what': 120,\n",
       " 'is': 121,\n",
       " \"alzheimer's\": 122,\n",
       " 'anxiety': 123,\n",
       " 'allergies': 124,\n",
       " 'stroke': 125,\n",
       " 'osteoporosis': 126,\n",
       " 'copd': 127,\n",
       " 'spices': 128,\n",
       " 'forms': 129,\n",
       " 'significance': 130,\n",
       " 'epics': 131,\n",
       " 'durga': 132,\n",
       " 'rama': 133,\n",
       " 'saraswati': 134,\n",
       " 'hanuman': 135,\n",
       " 'parvati': 136,\n",
       " 'brahma': 137,\n",
       " 'murugan': 138,\n",
       " 'knitting': 139,\n",
       " 'growing': 140,\n",
       " 'behavior': 141,\n",
       " 'space': 142,\n",
       " 'exercise': 143,\n",
       " 'cultural': 144,\n",
       " 'language': 145,\n",
       " 'ethics': 146,\n",
       " 'money': 147,\n",
       " 'design': 148,\n",
       " 'educational': 149,\n",
       " 'comedy': 150,\n",
       " 'friends': 151,\n",
       " 'animation': 152,\n",
       " 'junior': 153,\n",
       " 'crafts': 154,\n",
       " 'gods': 155,\n",
       " 'data': 156,\n",
       " 'anthropology': 157,\n",
       " 'linguistics': 158,\n",
       " 'ecology': 159,\n",
       " 'disease': 160,\n",
       " 'industrial': 161,\n",
       " 'social': 162,\n",
       " 'development': 163,\n",
       " 'studies': 164,\n",
       " 'multiplayer': 165,\n",
       " 'fantasy': 166,\n",
       " 'minecraft': 167,\n",
       " 'star': 168,\n",
       " 'wars': 169,\n",
       " 'jokes': 170,\n",
       " 'channel': 171,\n",
       " 'projects': 172,\n",
       " 'heart': 173,\n",
       " 'asthma': 174,\n",
       " 'pneumonia': 175,\n",
       " 'depression': 176,\n",
       " 'cancer': 177,\n",
       " 'back': 178,\n",
       " 'pain': 179,\n",
       " 'independence': 180,\n",
       " 'gupta': 181,\n",
       " 'british': 182,\n",
       " 'maurya': 183,\n",
       " 'trade': 184,\n",
       " 'ram': 185,\n",
       " 'bhajan': 186,\n",
       " 'symbolism': 187,\n",
       " 'scarf': 188,\n",
       " 'rockies': 189,\n",
       " 'mediterranean': 190,\n",
       " 'diet': 191,\n",
       " 'tomatoes': 192,\n",
       " 'indoors': 193,\n",
       " 'small': 194,\n",
       " 'closet': 195,\n",
       " 'poses': 196,\n",
       " 'skincare': 197,\n",
       " 'gardening': 198,\n",
       " 'pasta': 199,\n",
       " 'digital': 200,\n",
       " 'files': 201,\n",
       " 'make': 202,\n",
       " 'candles': 203,\n",
       " 'making': 204,\n",
       " 'improving': 205,\n",
       " 'posture': 206,\n",
       " 'foodies': 207,\n",
       " 'photography': 208,\n",
       " 'renovation': 209,\n",
       " 'works': 210,\n",
       " 'shakespeare': 211,\n",
       " 'start': 212,\n",
       " 'vegetable': 213,\n",
       " 'starting': 214,\n",
       " 'saving': 215,\n",
       " 'groceries': 216,\n",
       " 'novels': 217,\n",
       " 'read': 218,\n",
       " 'must': 219,\n",
       " 'dessert': 220,\n",
       " 'better': 221,\n",
       " 'sleep': 222,\n",
       " 'budget': 223,\n",
       " 'cleaning': 224,\n",
       " 'modern': 225,\n",
       " 'succulents': 226,\n",
       " 'soap': 227,\n",
       " 'workout': 228,\n",
       " 'programs': 229,\n",
       " 'surrealist': 230,\n",
       " 'plant': 231,\n",
       " 'painting': 232,\n",
       " 'beauty': 233,\n",
       " 'products': 234,\n",
       " 'paintings': 235,\n",
       " 'compost': 236,\n",
       " 'pile': 237,\n",
       " 'watch': 238,\n",
       " 'vegetarian': 239,\n",
       " 'decluttering': 240,\n",
       " 'podcasts': 241,\n",
       " 'crochet': 242,\n",
       " 'hair': 243,\n",
       " 'contemporary': 244,\n",
       " 'herb': 245,\n",
       " 'mechanics': 246,\n",
       " 'civilization': 247,\n",
       " 'human': 248,\n",
       " 'astronomy': 249,\n",
       " 'computer': 250,\n",
       " 'planets': 251,\n",
       " 'robotics': 252,\n",
       " 'logic': 253,\n",
       " 'literature': 254,\n",
       " 'dinosaurs': 255,\n",
       " 'neuroscience': 256,\n",
       " 'brain': 257,\n",
       " 'system': 258,\n",
       " 'city': 259,\n",
       " 'computational': 260,\n",
       " 'cinema': 261,\n",
       " 'movement': 262,\n",
       " 'civilizations': 263,\n",
       " 'architectural': 264,\n",
       " 'superheroes': 265,\n",
       " 'taylor': 266,\n",
       " 'swift': 267,\n",
       " 'usa': 268,\n",
       " 'sci': 269,\n",
       " 'fi': 270,\n",
       " 'rapper': 271,\n",
       " 'mario': 272,\n",
       " 'pages': 273,\n",
       " \"children's\": 274,\n",
       " 'pixar': 275,\n",
       " 'nintendo': 276,\n",
       " 'family': 277,\n",
       " 'toddlers': 278,\n",
       " 'sounds': 279,\n",
       " 'on': 280,\n",
       " 'list': 281,\n",
       " 'apps': 282,\n",
       " 'impact': 283,\n",
       " 'festival': 284,\n",
       " 'renewable': 285,\n",
       " 'energy': 286,\n",
       " 'sustainability': 287,\n",
       " 'mind': 288,\n",
       " 'archaeology': 289,\n",
       " 'big': 290,\n",
       " 'markets': 291,\n",
       " 'molecules': 292,\n",
       " 'nutrition': 293,\n",
       " 'stars': 294,\n",
       " 'civil': 295,\n",
       " 'genetics': 296,\n",
       " 'environmental': 297,\n",
       " 'sociology': 298,\n",
       " 'geometry': 299,\n",
       " 'teaching': 300,\n",
       " 'linguistic': 301,\n",
       " 'optimization': 302,\n",
       " 'game': 303,\n",
       " 'security': 304,\n",
       " 'interaction': 305,\n",
       " 'urban': 306,\n",
       " 'criminal': 307,\n",
       " 'forensic': 308,\n",
       " 'cognitive': 309,\n",
       " 'media': 310,\n",
       " 'behavioral': 311,\n",
       " 'industry': 312,\n",
       " 'aerospace': 313,\n",
       " 'business': 314,\n",
       " 'avengers': 315,\n",
       " 'endgame': 316,\n",
       " 'fortnite': 317,\n",
       " 'paris': 318,\n",
       " 'france': 319,\n",
       " 'witcher': 320,\n",
       " 'stranger': 321,\n",
       " 'things': 322,\n",
       " 'beyoncé': 323,\n",
       " 'spain': 324,\n",
       " 'harry': 325,\n",
       " 'potter': 326,\n",
       " 'simulation': 327,\n",
       " 'marvel': 328,\n",
       " 'super': 329,\n",
       " 'asia': 330,\n",
       " 'pokémon': 331,\n",
       " 'cast': 332,\n",
       " 'prehistoric': 333,\n",
       " 'rhymes': 334,\n",
       " 'humor': 335,\n",
       " 'reading': 336,\n",
       " 'paw': 337,\n",
       " 'patrol': 338,\n",
       " 'baby': 339,\n",
       " 'cute': 340,\n",
       " 'pj': 341,\n",
       " 'masks': 342,\n",
       " 'sesame': 343,\n",
       " 'street': 344,\n",
       " 'solar': 345,\n",
       " 'toy': 346,\n",
       " 'story': 347,\n",
       " 'ninjago': 348,\n",
       " 'disneyland': 349,\n",
       " 'children': 350,\n",
       " 'habitats': 351,\n",
       " 'princess': 352,\n",
       " 'karaoke': 353,\n",
       " 'bedtime': 354,\n",
       " 'virtual': 355,\n",
       " 'tours': 356,\n",
       " 'flu': 357,\n",
       " 'migraine': 358,\n",
       " 'attack': 359,\n",
       " 'mughal': 360,\n",
       " 'raj': 361,\n",
       " 'buddhism': 362,\n",
       " 'freedom': 363,\n",
       " 'fighters': 364,\n",
       " 'sikhism': 365,\n",
       " 'vijayanagara': 366,\n",
       " 'leaders': 367,\n",
       " 'ocean': 368,\n",
       " 'chola': 369,\n",
       " 'colonization': 370,\n",
       " 'indus': 371,\n",
       " 'valley': 372,\n",
       " 'heritage': 373,\n",
       " 'maratha': 374,\n",
       " 'ashoka': 375,\n",
       " 'styles': 376,\n",
       " 'indo': 377,\n",
       " 'greek': 378,\n",
       " 'kingdom': 379,\n",
       " 'delhi': 380,\n",
       " 'sultanate': 381,\n",
       " 'women': 382,\n",
       " 'classical': 383,\n",
       " 'rajputs': 384,\n",
       " 'cuisine': 385,\n",
       " 'decline': 386,\n",
       " 'dynasty': 387,\n",
       " 'routes': 388,\n",
       " 'ganesha': 389,\n",
       " 'lingam': 390,\n",
       " 'ritual': 391,\n",
       " 'avatars': 392,\n",
       " 'chalisa': 393,\n",
       " 'creator': 394,\n",
       " 'aarti': 395,\n",
       " 'festivals': 396,\n",
       " 'childhood': 397,\n",
       " 'knit': 398,\n",
       " 'grow': 399,\n",
       " 'everyone': 400,\n",
       " 'should': 401,\n",
       " 'friendly': 402,\n",
       " 'your': 403,\n",
       " 'artificial': 404,\n",
       " 'intelligence': 405,\n",
       " 'future': 406,\n",
       " 'machine': 407,\n",
       " 'algorithm': 408,\n",
       " 'world': 409,\n",
       " 'war': 410,\n",
       " 'ii': 411,\n",
       " 'military': 412,\n",
       " 'climate': 413,\n",
       " 'change': 414,\n",
       " 'global': 415,\n",
       " 'warming': 416,\n",
       " 'analytics': 417,\n",
       " 'anatomy': 418,\n",
       " 'body': 419,\n",
       " 'exploration': 420,\n",
       " 'nasa': 421,\n",
       " 'microeconomics': 422,\n",
       " 'political': 423,\n",
       " 'government': 424,\n",
       " 'policy': 425,\n",
       " 'organic': 426,\n",
       " 'carbon': 427,\n",
       " 'european': 428,\n",
       " 'programming': 429,\n",
       " 'coding': 430,\n",
       " 'software': 431,\n",
       " 'fitness': 432,\n",
       " 'structures': 433,\n",
       " 'construction': 434,\n",
       " 'traditions': 435,\n",
       " 'grammar': 436,\n",
       " 'evolutionary': 437,\n",
       " 'species': 438,\n",
       " 'languages': 439,\n",
       " 'script': 440,\n",
       " 'translation': 441,\n",
       " 'automation': 442,\n",
       " 'pollution': 443,\n",
       " 'poetry': 444,\n",
       " 'paleontology': 445,\n",
       " 'fossils': 446,\n",
       " 'dna': 447,\n",
       " 'inheritance': 448,\n",
       " 'excavation': 449,\n",
       " 'numbers': 450,\n",
       " 'maps': 451,\n",
       " 'landforms': 452,\n",
       " 'matter': 453,\n",
       " 'elements': 454,\n",
       " 'compounds': 455,\n",
       " 'zoology': 456,\n",
       " 'organisms': 457,\n",
       " 'botany': 458,\n",
       " 'plants': 459,\n",
       " 'ecosystems': 460,\n",
       " 'events': 461,\n",
       " 'eras': 462,\n",
       " 'nervous': 463,\n",
       " 'buildings': 464,\n",
       " 'marine': 465,\n",
       " 'oceans': 466,\n",
       " 'aquatic': 467,\n",
       " 'life': 468,\n",
       " 'public': 469,\n",
       " 'geology': 470,\n",
       " 'rocks': 471,\n",
       " 'earthquakes': 472,\n",
       " 'consciousness': 473,\n",
       " 'systems': 474,\n",
       " 'strategic': 475,\n",
       " 'cybersecurity': 476,\n",
       " 'fashion': 477,\n",
       " 'clothing': 478,\n",
       " 'style': 479,\n",
       " 'computing': 480,\n",
       " 'planning': 481,\n",
       " 'bioinformatics': 482,\n",
       " 'genomics': 483,\n",
       " 'scientific': 484,\n",
       " 'method': 485,\n",
       " 'film': 486,\n",
       " 'operations': 487,\n",
       " 'research': 488,\n",
       " 'musical': 489,\n",
       " 'composition': 490,\n",
       " 'harmony': 491,\n",
       " 'cryptography': 492,\n",
       " 'encryption': 493,\n",
       " 'developmental': 494,\n",
       " 'child': 495,\n",
       " 'aging': 496,\n",
       " 'rights': 497,\n",
       " 'equality': 498,\n",
       " 'justice': 499,\n",
       " 'communication': 500,\n",
       " 'mass': 501,\n",
       " 'vision': 502,\n",
       " 'image': 503,\n",
       " 'processing': 504,\n",
       " 'ai': 505,\n",
       " 'semantics': 506,\n",
       " 'product': 507,\n",
       " 'particles': 508,\n",
       " 'interactions': 509,\n",
       " 'usability': 510,\n",
       " 'organizational': 511,\n",
       " 'organization': 512,\n",
       " 'workplace': 513,\n",
       " 'archaeoastronomy': 514,\n",
       " 'biochemistry': 515,\n",
       " 'morphology': 516,\n",
       " 'biomechanics': 517,\n",
       " 'cognition': 518,\n",
       " 'green': 519,\n",
       " 'geopolitics': 520,\n",
       " 'politics': 521,\n",
       " 'mathematical': 522,\n",
       " 'crime': 523,\n",
       " 'evidence': 524,\n",
       " 'field': 525,\n",
       " 'urbanization': 526,\n",
       " 'astrophysics': 527,\n",
       " 'cosmology': 528,\n",
       " 'medical': 529,\n",
       " 'medicine': 530,\n",
       " 'religious': 531,\n",
       " 'religion': 532,\n",
       " 'string': 533,\n",
       " 'information': 534,\n",
       " 'computers': 535,\n",
       " 'revolution': 536,\n",
       " 'work': 537,\n",
       " 'community': 538,\n",
       " 'counseling': 539,\n",
       " 'algebraic': 540,\n",
       " 'topology': 541,\n",
       " 'algebra': 542,\n",
       " 'resource': 543,\n",
       " 'management': 544,\n",
       " 'food': 545,\n",
       " 'economic': 546,\n",
       " 'cell': 547,\n",
       " 'cells': 548,\n",
       " 'ed': 549,\n",
       " 'sheeran': 550,\n",
       " 'new': 551,\n",
       " 'york': 552,\n",
       " 'fiction': 553,\n",
       " 'call': 554,\n",
       " 'duty': 555,\n",
       " 'shooting': 556,\n",
       " 'ariana': 557,\n",
       " 'grande': 558,\n",
       " 'tokyo': 559,\n",
       " 'japan': 560,\n",
       " 'mandalorian': 561,\n",
       " 'fifa': 562,\n",
       " '22': 563,\n",
       " 'sports': 564,\n",
       " 'rome': 565,\n",
       " 'italy': 566,\n",
       " 'black': 567,\n",
       " 'mirror': 568,\n",
       " 'among': 569,\n",
       " 'us': 570,\n",
       " 'drake': 571,\n",
       " 'london': 572,\n",
       " 'england': 573,\n",
       " 'office': 574,\n",
       " 'overwatch': 575,\n",
       " 'shooter': 576,\n",
       " 'billie': 577,\n",
       " 'eilish': 578,\n",
       " 'barcelona': 579,\n",
       " 'breaking': 580,\n",
       " 'bad': 581,\n",
       " 'drama': 582,\n",
       " 'league': 583,\n",
       " 'legends': 584,\n",
       " 'moba': 585,\n",
       " 'post': 586,\n",
       " 'malone': 587,\n",
       " 'sydney': 588,\n",
       " 'australia': 589,\n",
       " 'crossing': 590,\n",
       " 'hawaii': 591,\n",
       " 'zelda': 592,\n",
       " 'adventure': 593,\n",
       " 'pop': 594,\n",
       " 'genre': 595,\n",
       " 'dubai': 596,\n",
       " 'uae': 597,\n",
       " 'sims': 598,\n",
       " 'eminem': 599,\n",
       " 'greece': 600,\n",
       " 'thrones': 601,\n",
       " 'platformer': 602,\n",
       " 'adele': 603,\n",
       " 'thailand': 604,\n",
       " 'simpsons': 605,\n",
       " 'anime': 606,\n",
       " 'coldplay': 607,\n",
       " 'band': 608,\n",
       " 'brazil': 609,\n",
       " 'south': 610,\n",
       " 'america': 611,\n",
       " 'bang': 612,\n",
       " 'lady': 613,\n",
       " 'gaga': 614,\n",
       " 'china': 615,\n",
       " 'episodes': 616,\n",
       " 'kart': 617,\n",
       " 'racing': 618,\n",
       " 'cartoon': 619,\n",
       " 'network': 620,\n",
       " 'dinosaur': 621,\n",
       " 'spongebob': 622,\n",
       " 'squarepants': 623,\n",
       " 'nursery': 624,\n",
       " 'princesses': 625,\n",
       " 'cards': 626,\n",
       " 'craft': 627,\n",
       " 'switch': 628,\n",
       " 'with': 629,\n",
       " 'lyrics': 630,\n",
       " 'rides': 631,\n",
       " 'attractions': 632,\n",
       " 'themepark': 633,\n",
       " 'thomas': 634,\n",
       " 'netflix': 635,\n",
       " 'streaming': 636,\n",
       " 'fun': 637,\n",
       " 'riddles': 638,\n",
       " 'printable': 639,\n",
       " 'at': 640,\n",
       " 'app': 641,\n",
       " 'dress': 642,\n",
       " 'up': 643,\n",
       " 'batman': 644,\n",
       " 'preschoolers': 645,\n",
       " 'movie': 646,\n",
       " 'marathon': 647,\n",
       " 'outdoor': 648,\n",
       " 'outdoors': 649,\n",
       " 'sheets': 650,\n",
       " 'technic': 651,\n",
       " 'high': 652,\n",
       " 'blood': 653,\n",
       " 'pressure': 654,\n",
       " 'great': 655,\n",
       " 'Artificial': 525,\n",
       " 'Quantum': 526,\n",
       " 'Renewable': 527,\n",
       " 'Machine': 528,\n",
       " 'World': 529,\n",
       " 'War': 530,\n",
       " 'II': 531,\n",
       " 'Climate': 532,\n",
       " 'Psychology': 533,\n",
       " 'Ancient': 534,\n",
       " 'Data': 535,\n",
       " 'Human': 536,\n",
       " 'Space': 537,\n",
       " 'Microeconomics': 538,\n",
       " 'Political': 539,\n",
       " 'Organic': 540,\n",
       " 'European': 541,\n",
       " 'Computer': 542,\n",
       " 'Health': 543,\n",
       " 'Astronomy': 544,\n",
       " 'Civil': 545,\n",
       " 'Cultural': 546,\n",
       " 'Linguistics': 547,\n",
       " 'Evolutionary': 548,\n",
       " 'Robotics': 549,\n",
       " 'Environmental': 550,\n",
       " 'Philosophy': 551,\n",
       " 'Literature': 552,\n",
       " 'Sociology': 553,\n",
       " 'Paleontology': 554,\n",
       " 'Genetics': 555,\n",
       " 'Archaeology': 556,\n",
       " 'Mathematics': 557,\n",
       " 'Economics': 558,\n",
       " 'Geography': 559,\n",
       " 'Physics': 560,\n",
       " 'Chemistry': 561,\n",
       " 'Zoology': 562,\n",
       " 'Botany': 563,\n",
       " 'History': 564,\n",
       " 'Neuroscience': 565,\n",
       " 'Education': 566,\n",
       " 'Architecture': 567,\n",
       " 'Engineering': 568,\n",
       " 'Linguistic': 569,\n",
       " 'Marine': 570,\n",
       " 'Public': 571,\n",
       " 'Geology': 572,\n",
       " 'Industrial': 573,\n",
       " 'Art': 574,\n",
       " 'Game': 575,\n",
       " 'Cybersecurity': 576,\n",
       " 'Fashion': 577,\n",
       " 'Social': 578,\n",
       " 'Urban': 579,\n",
       " 'Bioinformatics': 580,\n",
       " 'Criminal': 581,\n",
       " 'Film': 582,\n",
       " 'Operations': 583,\n",
       " 'Cognitive': 584,\n",
       " 'Music': 585,\n",
       " 'Cryptography': 586,\n",
       " 'Developmental': 587,\n",
       " 'Media': 588,\n",
       " 'Behavioral': 589,\n",
       " 'Educational': 590,\n",
       " 'Human-computer': 591,\n",
       " 'Organizational': 592,\n",
       " 'Archaeoastronomy': 593,\n",
       " 'Biochemistry': 594,\n",
       " 'Biomechanics': 595,\n",
       " 'Green': 596,\n",
       " 'Geopolitics': 597,\n",
       " 'Mathematical': 598,\n",
       " 'Forensic': 599,\n",
       " 'Astrophysics': 600,\n",
       " 'Medical': 601,\n",
       " 'Computational': 602,\n",
       " 'Religious': 603,\n",
       " 'String': 604,\n",
       " 'Development': 605,\n",
       " 'Information': 606,\n",
       " 'Algebraic': 607,\n",
       " 'Aerospace': 608,\n",
       " 'Food': 609,\n",
       " 'Economic': 610,\n",
       " 'Cell': 611,\n",
       " 'Ethics': 612,\n",
       " 'Architectural': 613,\n",
       " 'Avengers:': 614,\n",
       " 'Endgame': 615,\n",
       " 'Fortnite': 616,\n",
       " 'Taylor': 617,\n",
       " 'Swift': 618,\n",
       " 'Paris': 619,\n",
       " 'The': 620,\n",
       " 'Witcher': 621,\n",
       " 'Minecraft': 622,\n",
       " 'Ed': 623,\n",
       " 'Sheeran': 624,\n",
       " 'New': 625,\n",
       " 'York': 626,\n",
       " 'City': 627,\n",
       " 'Stranger': 628,\n",
       " 'Things': 629,\n",
       " 'Call': 630,\n",
       " 'Duty': 631,\n",
       " 'Ariana': 632,\n",
       " 'Grande': 633,\n",
       " 'Tokyo': 634,\n",
       " 'Mandalorian': 635,\n",
       " 'FIFA': 636,\n",
       " 'Beyoncé': 637,\n",
       " 'Rome': 638,\n",
       " 'Black': 639,\n",
       " 'Mirror': 640,\n",
       " 'Among': 641,\n",
       " 'Us': 642,\n",
       " 'Drake': 643,\n",
       " 'London': 644,\n",
       " 'Office': 645,\n",
       " 'Overwatch': 646,\n",
       " 'Billie': 647,\n",
       " 'Eilish': 648,\n",
       " 'Barcelona': 649,\n",
       " 'Breaking': 650,\n",
       " 'Bad': 651,\n",
       " 'League': 652,\n",
       " 'Legends': 653,\n",
       " 'Post': 654,\n",
       " 'Malone': 655,\n",
       " 'Sydney': 656,\n",
       " 'Friends': 657,\n",
       " 'Harry': 658,\n",
       " 'Potter': 659,\n",
       " 'Animal': 660,\n",
       " 'Crossing': 661,\n",
       " 'Hawaii': 662,\n",
       " 'Marvel': 663,\n",
       " 'Zelda': 664,\n",
       " 'Pop': 665,\n",
       " 'Dubai': 666,\n",
       " 'Star': 667,\n",
       " 'Wars': 668,\n",
       " 'Sims': 669,\n",
       " 'Eminem': 670,\n",
       " 'Greece': 671,\n",
       " 'Thrones': 672,\n",
       " 'Super': 673,\n",
       " 'Mario': 674,\n",
       " 'Adele': 675,\n",
       " 'Thailand': 676,\n",
       " 'Simpsons': 677,\n",
       " 'Pokémon': 678,\n",
       " 'Coldplay': 679,\n",
       " 'Brazil': 680,\n",
       " 'Big': 681,\n",
       " 'Bang': 682,\n",
       " 'Theory': 683,\n",
       " 'Lady': 684,\n",
       " 'Gaga': 685,\n",
       " 'China': 686,\n",
       " 'Kart': 687,\n",
       " 'Spain': 688,\n",
       " 'Disney': 689,\n",
       " 'LEGO': 690,\n",
       " 'Cartoon': 691,\n",
       " 'Network': 692,\n",
       " 'Dinosaur': 693,\n",
       " 'SpongeBob': 694,\n",
       " 'SquarePants': 695,\n",
       " 'Nursery': 696,\n",
       " 'Kids': 697,\n",
       " 'Coloring': 698,\n",
       " 'Channel': 699,\n",
       " \"Children's\": 700,\n",
       " 'Magic': 701,\n",
       " 'Junior': 702,\n",
       " 'Paw': 703,\n",
       " 'Patrol': 704,\n",
       " 'Science': 705,\n",
       " 'Baby': 706,\n",
       " 'PJ': 707,\n",
       " 'Masks': 708,\n",
       " 'Sesame': 709,\n",
       " 'Street': 710,\n",
       " 'Pixar': 711,\n",
       " 'Solar': 712,\n",
       " 'Toy': 713,\n",
       " 'Story': 714,\n",
       " 'Ninjago': 715,\n",
       " 'Disneyland': 716,\n",
       " 'Nintendo': 717,\n",
       " 'Switch': 718,\n",
       " 'Learning': 719,\n",
       " 'Thomas': 720,\n",
       " 'Netflix': 721,\n",
       " 'Fun': 722,\n",
       " 'Batman': 723,\n",
       " 'Technic': 724,\n",
       " 'What': 725,\n",
       " 'Symptoms': 726,\n",
       " 'Treatment': 727,\n",
       " 'Causes': 728,\n",
       " 'How': 729,\n",
       " \"Alzheimer's\": 730,\n",
       " 'COPD': 731,\n",
       " 'India': 732,\n",
       " 'Indian': 733,\n",
       " 'Mughal': 734,\n",
       " 'Empire': 735,\n",
       " 'Independence': 736,\n",
       " 'Hinduism': 737,\n",
       " 'Gupta': 738,\n",
       " 'British': 739,\n",
       " 'Raj': 740,\n",
       " 'Buddhism': 741,\n",
       " 'Maurya': 742,\n",
       " 'Sikhism': 743,\n",
       " 'Vijayanagara': 744,\n",
       " 'Ocean': 745,\n",
       " 'Chola': 746,\n",
       " 'Impact': 747,\n",
       " 'Indus': 748,\n",
       " 'Valley': 749,\n",
       " 'Civilization': 750,\n",
       " 'Maratha': 751,\n",
       " 'Ashoka': 752,\n",
       " 'Great': 753,\n",
       " 'Indo-Greek': 754,\n",
       " 'Kingdom': 755,\n",
       " 'Influence': 756,\n",
       " 'Delhi': 757,\n",
       " 'Sultanate': 758,\n",
       " 'Women': 759,\n",
       " 'Rajputs': 760,\n",
       " 'Decline': 761,\n",
       " 'Dynasty': 762,\n",
       " 'Trade': 763,\n",
       " 'Artifacts': 764,\n",
       " 'Significance': 765,\n",
       " 'Lord': 766,\n",
       " 'Shiva': 767,\n",
       " 'Goddess': 768,\n",
       " 'Lakshmi': 769,\n",
       " 'Vishnu': 770,\n",
       " 'Krishna': 771,\n",
       " 'Durga': 772,\n",
       " 'Rama': 773,\n",
       " 'Ganesha': 774,\n",
       " 'Saraswati': 775,\n",
       " 'Hanuman': 776,\n",
       " 'Parvati': 777,\n",
       " 'Brahma': 778,\n",
       " 'Kali': 779,\n",
       " 'Murugan': 780,\n",
       " 'Radha': 781,\n",
       " 'Sita': 782,\n",
       " 'Lingam': 783,\n",
       " 'Chalisa': 784,\n",
       " 'Ram': 785,\n",
       " 'Best': 786,\n",
       " 'Rockies': 787,\n",
       " 'DIY': 788,\n",
       " 'Mediterranean': 789,\n",
       " 'Tips': 790,\n",
       " 'Beginner': 791,\n",
       " 'Famous': 792,\n",
       " 'Indoor': 793,\n",
       " 'Easy': 794,\n",
       " 'Shakespeare': 795,\n",
       " 'Classic': 796,\n",
       " 'budget-friendly': 797,\n",
       " 'Europe': 798,\n",
       " 'NASA': 799,\n",
       " 'DNA': 800,\n",
       " 'AI': 801,\n",
       " 'France': 802,\n",
       " 'TV': 803,\n",
       " 'USA': 804,\n",
       " 'Japan': 805,\n",
       " 'sci-fi': 806,\n",
       " 'Italy': 807,\n",
       " 'England': 808,\n",
       " 'MOBA': 809,\n",
       " 'Australia': 810,\n",
       " 'UAE': 811,\n",
       " 'Asia': 812,\n",
       " 'South': 813,\n",
       " 'America': 814,\n",
       " 'Hindu': 815,\n",
       " 'Puja': 816,\n",
       " 'Mantra': 817,\n",
       " 'Bhajan': 818,\n",
       " 'Aarti': 819,\n",
       " 'must-read': 820,\n",
       " 'must-watch': 821}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "570538aa-aa03-464c-8251-761db4194a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/konda.sandeep/Projects/personal/major project/backend/env/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 9 variables whereas the saved optimizer has 16 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "keras.saving.save_model(model, '../models/model_final.keras', overwrite=True)\n",
    "loaded_model = keras.saving.load_model(\"model1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf77c2cb-3610-4558-9190-d1388ece3edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.53092563],\n",
       "       [0.5309241 ],\n",
       "       [0.53092563],\n",
       "       [0.5309247 ],\n",
       "       [0.5309243 ],\n",
       "       [0.5309263 ],\n",
       "       [0.5309261 ],\n",
       "       [0.5309266 ],\n",
       "       [0.53092647],\n",
       "       [0.5309255 ],\n",
       "       [0.53092563],\n",
       "       [0.53092504],\n",
       "       [0.5309261 ],\n",
       "       [0.5309258 ],\n",
       "       [0.53092706],\n",
       "       [0.53092563],\n",
       "       [0.5309266 ],\n",
       "       [0.5309249 ],\n",
       "       [0.53092486],\n",
       "       [0.5309252 ],\n",
       "       [0.53092587],\n",
       "       [0.53092545],\n",
       "       [0.5309255 ],\n",
       "       [0.5309253 ],\n",
       "       [0.5309255 ],\n",
       "       [0.5309243 ],\n",
       "       [0.53092456],\n",
       "       [0.530926  ],\n",
       "       [0.5309255 ],\n",
       "       [0.53092545],\n",
       "       [0.53092444],\n",
       "       [0.5309253 ],\n",
       "       [0.53092486],\n",
       "       [0.53092515],\n",
       "       [0.5309243 ],\n",
       "       [0.5309249 ],\n",
       "       [0.5309248 ],\n",
       "       [0.5309252 ],\n",
       "       [0.5309254 ],\n",
       "       [0.53092587],\n",
       "       [0.53092456],\n",
       "       [0.5309248 ],\n",
       "       [0.5309251 ],\n",
       "       [0.53092635],\n",
       "       [0.530926  ],\n",
       "       [0.5309242 ],\n",
       "       [0.5309248 ],\n",
       "       [0.53092575],\n",
       "       [0.53092617],\n",
       "       [0.53092587],\n",
       "       [0.5309269 ],\n",
       "       [0.5309253 ],\n",
       "       [0.53092444],\n",
       "       [0.5309235 ],\n",
       "       [0.53092635],\n",
       "       [0.5309261 ],\n",
       "       [0.5309273 ],\n",
       "       [0.5309261 ],\n",
       "       [0.53092504],\n",
       "       [0.5309255 ],\n",
       "       [0.5309266 ],\n",
       "       [0.53092563],\n",
       "       [0.5309254 ],\n",
       "       [0.530926  ],\n",
       "       [0.530926  ],\n",
       "       [0.53092647],\n",
       "       [0.5309253 ],\n",
       "       [0.5309268 ],\n",
       "       [0.530926  ],\n",
       "       [0.5309266 ],\n",
       "       [0.53092456],\n",
       "       [0.5309256 ],\n",
       "       [0.5309258 ],\n",
       "       [0.5309252 ],\n",
       "       [0.53092504],\n",
       "       [0.53092486],\n",
       "       [0.5309254 ],\n",
       "       [0.5309243 ],\n",
       "       [0.5309255 ],\n",
       "       [0.53092545],\n",
       "       [0.5309254 ],\n",
       "       [0.53092504],\n",
       "       [0.530926  ],\n",
       "       [0.530926  ],\n",
       "       [0.5309262 ],\n",
       "       [0.5309249 ],\n",
       "       [0.53092545],\n",
       "       [0.53092587],\n",
       "       [0.530924  ],\n",
       "       [0.53092563],\n",
       "       [0.5309248 ],\n",
       "       [0.530926  ],\n",
       "       [0.5309262 ],\n",
       "       [0.5309258 ],\n",
       "       [0.5309256 ],\n",
       "       [0.53092647],\n",
       "       [0.53092396],\n",
       "       [0.53092456],\n",
       "       [0.5309254 ],\n",
       "       [0.53092575],\n",
       "       [0.53092515],\n",
       "       [0.53092587],\n",
       "       [0.53092635],\n",
       "       [0.5309262 ],\n",
       "       [0.5309253 ],\n",
       "       [0.5309245 ],\n",
       "       [0.53092563],\n",
       "       [0.5309242 ],\n",
       "       [0.53092515],\n",
       "       [0.53092486],\n",
       "       [0.53092533],\n",
       "       [0.53092587],\n",
       "       [0.5309261 ],\n",
       "       [0.5309257 ],\n",
       "       [0.5309253 ],\n",
       "       [0.53092426],\n",
       "       [0.53092486],\n",
       "       [0.53092706],\n",
       "       [0.53092504],\n",
       "       [0.53092444],\n",
       "       [0.53092474],\n",
       "       [0.5309268 ],\n",
       "       [0.53092575],\n",
       "       [0.53092533],\n",
       "       [0.530924  ],\n",
       "       [0.5309268 ],\n",
       "       [0.53092515],\n",
       "       [0.5309244 ],\n",
       "       [0.53092647],\n",
       "       [0.53092635],\n",
       "       [0.53092587],\n",
       "       [0.53092414],\n",
       "       [0.5309247 ],\n",
       "       [0.53092647],\n",
       "       [0.53092504],\n",
       "       [0.5309247 ],\n",
       "       [0.53092504],\n",
       "       [0.5309267 ],\n",
       "       [0.5309262 ],\n",
       "       [0.53092474],\n",
       "       [0.53092575],\n",
       "       [0.53092563],\n",
       "       [0.5309257 ],\n",
       "       [0.5309253 ],\n",
       "       [0.53092426],\n",
       "       [0.53092486],\n",
       "       [0.53092706],\n",
       "       [0.53092426],\n",
       "       [0.5309248 ],\n",
       "       [0.53092504],\n",
       "       [0.53092515],\n",
       "       [0.53092575],\n",
       "       [0.5309254 ],\n",
       "       [0.5309257 ],\n",
       "       [0.5309257 ],\n",
       "       [0.53092545],\n",
       "       [0.53092563],\n",
       "       [0.5309237 ],\n",
       "       [0.53092635],\n",
       "       [0.5309274 ],\n",
       "       [0.5309254 ],\n",
       "       [0.5309248 ],\n",
       "       [0.5309247 ],\n",
       "       [0.5309263 ],\n",
       "       [0.5309254 ],\n",
       "       [0.5309241 ],\n",
       "       [0.53092617],\n",
       "       [0.53092605],\n",
       "       [0.53092575],\n",
       "       [0.5309247 ],\n",
       "       [0.53092384],\n",
       "       [0.53092587],\n",
       "       [0.5309255 ],\n",
       "       [0.5309253 ],\n",
       "       [0.53092575],\n",
       "       [0.53092635],\n",
       "       [0.5309255 ],\n",
       "       [0.5309254 ],\n",
       "       [0.5309263 ],\n",
       "       [0.5309252 ],\n",
       "       [0.5309261 ],\n",
       "       [0.53092486],\n",
       "       [0.53092504],\n",
       "       [0.53092563],\n",
       "       [0.5309255 ],\n",
       "       [0.530926  ],\n",
       "       [0.53092575],\n",
       "       [0.53092575],\n",
       "       [0.53092515],\n",
       "       [0.5309267 ],\n",
       "       [0.530926  ],\n",
       "       [0.5309258 ],\n",
       "       [0.53092545],\n",
       "       [0.5309255 ],\n",
       "       [0.530926  ],\n",
       "       [0.5309242 ],\n",
       "       [0.5309258 ],\n",
       "       [0.5309248 ],\n",
       "       [0.5309253 ],\n",
       "       [0.53092563],\n",
       "       [0.5309254 ],\n",
       "       [0.5309261 ],\n",
       "       [0.5309261 ],\n",
       "       [0.5309259 ],\n",
       "       [0.53092563],\n",
       "       [0.5309257 ],\n",
       "       [0.5309247 ],\n",
       "       [0.53092575],\n",
       "       [0.5309267 ],\n",
       "       [0.530926  ],\n",
       "       [0.530926  ],\n",
       "       [0.530924  ],\n",
       "       [0.5309255 ],\n",
       "       [0.5309242 ],\n",
       "       [0.530926  ],\n",
       "       [0.53092504],\n",
       "       [0.5309268 ],\n",
       "       [0.5309255 ],\n",
       "       [0.53092504],\n",
       "       [0.5309255 ],\n",
       "       [0.53092587],\n",
       "       [0.530926  ],\n",
       "       [0.53092647],\n",
       "       [0.5309255 ],\n",
       "       [0.53092575],\n",
       "       [0.5309242 ],\n",
       "       [0.5309258 ],\n",
       "       [0.5309248 ],\n",
       "       [0.5309253 ],\n",
       "       [0.53092575],\n",
       "       [0.5309254 ],\n",
       "       [0.5309261 ],\n",
       "       [0.5309261 ],\n",
       "       [0.5309259 ],\n",
       "       [0.53092563],\n",
       "       [0.53092575],\n",
       "       [0.5309262 ],\n",
       "       [0.53092635],\n",
       "       [0.5309257 ],\n",
       "       [0.53092515],\n",
       "       [0.5309257 ],\n",
       "       [0.5309254 ],\n",
       "       [0.5309255 ],\n",
       "       [0.5309253 ],\n",
       "       [0.5309254 ],\n",
       "       [0.5309253 ],\n",
       "       [0.53092587],\n",
       "       [0.5309241 ],\n",
       "       [0.53092605],\n",
       "       [0.5309261 ],\n",
       "       [0.53092515],\n",
       "       [0.53092563],\n",
       "       [0.53092515],\n",
       "       [0.5309262 ],\n",
       "       [0.5309255 ],\n",
       "       [0.53092504],\n",
       "       [0.5309254 ],\n",
       "       [0.5309274 ],\n",
       "       [0.53092533],\n",
       "       [0.5309256 ],\n",
       "       [0.5309257 ],\n",
       "       [0.5309246 ],\n",
       "       [0.5309256 ],\n",
       "       [0.5309248 ],\n",
       "       [0.530925  ],\n",
       "       [0.5309249 ],\n",
       "       [0.5309253 ],\n",
       "       [0.530925  ],\n",
       "       [0.5309254 ],\n",
       "       [0.5309252 ],\n",
       "       [0.5309262 ],\n",
       "       [0.5309247 ],\n",
       "       [0.53092456],\n",
       "       [0.5309257 ],\n",
       "       [0.53092456],\n",
       "       [0.53092587],\n",
       "       [0.53092504],\n",
       "       [0.53092635],\n",
       "       [0.530926  ],\n",
       "       [0.53092694],\n",
       "       [0.5309253 ],\n",
       "       [0.5309256 ],\n",
       "       [0.5309253 ],\n",
       "       [0.530926  ],\n",
       "       [0.53092647],\n",
       "       [0.5309255 ],\n",
       "       [0.5309249 ],\n",
       "       [0.5309253 ],\n",
       "       [0.530926  ],\n",
       "       [0.5309245 ],\n",
       "       [0.53092635],\n",
       "       [0.53092575],\n",
       "       [0.5309251 ],\n",
       "       [0.5309269 ],\n",
       "       [0.5309247 ],\n",
       "       [0.5309259 ],\n",
       "       [0.5309254 ],\n",
       "       [0.53092647],\n",
       "       [0.53092706],\n",
       "       [0.530926  ],\n",
       "       [0.5309259 ],\n",
       "       [0.53092515],\n",
       "       [0.53092575],\n",
       "       [0.53092504],\n",
       "       [0.53092617],\n",
       "       [0.5309255 ],\n",
       "       [0.53092456],\n",
       "       [0.5309259 ],\n",
       "       [0.5309255 ],\n",
       "       [0.53092587],\n",
       "       [0.53092504],\n",
       "       [0.5309273 ],\n",
       "       [0.53092676],\n",
       "       [0.53092515],\n",
       "       [0.53092617],\n",
       "       [0.53092486],\n",
       "       [0.53092587],\n",
       "       [0.53092456],\n",
       "       [0.53092647],\n",
       "       [0.5309265 ],\n",
       "       [0.5309259 ],\n",
       "       [0.5309266 ],\n",
       "       [0.53092515],\n",
       "       [0.5309258 ],\n",
       "       [0.5309248 ],\n",
       "       [0.5309254 ],\n",
       "       [0.53092515],\n",
       "       [0.5309254 ],\n",
       "       [0.53092605],\n",
       "       [0.5309262 ],\n",
       "       [0.5309267 ],\n",
       "       [0.530925  ],\n",
       "       [0.5309264 ],\n",
       "       [0.5309248 ],\n",
       "       [0.5309268 ],\n",
       "       [0.53092515],\n",
       "       [0.53092617],\n",
       "       [0.5309262 ],\n",
       "       [0.53092456],\n",
       "       [0.5309263 ],\n",
       "       [0.53092664],\n",
       "       [0.5309248 ],\n",
       "       [0.5309259 ],\n",
       "       [0.53092444],\n",
       "       [0.5309249 ],\n",
       "       [0.5309262 ],\n",
       "       [0.5309261 ],\n",
       "       [0.5309242 ],\n",
       "       [0.5309265 ],\n",
       "       [0.53092676],\n",
       "       [0.5309272 ],\n",
       "       [0.53092754],\n",
       "       [0.5309262 ],\n",
       "       [0.5309255 ],\n",
       "       [0.53092587],\n",
       "       [0.5309247 ],\n",
       "       [0.5309264 ],\n",
       "       [0.5309267 ],\n",
       "       [0.53092754],\n",
       "       [0.53092825],\n",
       "       [0.530926  ],\n",
       "       [0.53092706],\n",
       "       [0.5309277 ],\n",
       "       [0.5309268 ],\n",
       "       [0.53092617],\n",
       "       [0.53092784],\n",
       "       [0.5309268 ],\n",
       "       [0.53092587],\n",
       "       [0.53092587],\n",
       "       [0.53092617],\n",
       "       [0.53092706],\n",
       "       [0.53092784],\n",
       "       [0.5309268 ],\n",
       "       [0.53092587],\n",
       "       [0.53092587],\n",
       "       [0.53092617],\n",
       "       [0.53092706],\n",
       "       [0.53092784],\n",
       "       [0.5309268 ],\n",
       "       [0.53092587],\n",
       "       [0.53092587],\n",
       "       [0.53092617],\n",
       "       [0.53092706],\n",
       "       [0.53092694],\n",
       "       [0.53092545],\n",
       "       [0.530926  ],\n",
       "       [0.53092676],\n",
       "       [0.5309268 ],\n",
       "       [0.5309262 ],\n",
       "       [0.5309272 ],\n",
       "       [0.5309266 ],\n",
       "       [0.53092617],\n",
       "       [0.530926  ],\n",
       "       [0.53092575],\n",
       "       [0.5309256 ],\n",
       "       [0.5309262 ],\n",
       "       [0.53092515],\n",
       "       [0.5309261 ],\n",
       "       [0.53092533],\n",
       "       [0.5309261 ],\n",
       "       [0.5309262 ],\n",
       "       [0.5309262 ],\n",
       "       [0.5309255 ],\n",
       "       [0.5309261 ],\n",
       "       [0.5309268 ],\n",
       "       [0.53092563],\n",
       "       [0.53092605],\n",
       "       [0.53092504],\n",
       "       [0.53092617],\n",
       "       [0.53092587],\n",
       "       [0.53092533],\n",
       "       [0.53092647],\n",
       "       [0.53092587],\n",
       "       [0.5309259 ],\n",
       "       [0.53092617],\n",
       "       [0.5309254 ],\n",
       "       [0.5309258 ],\n",
       "       [0.5309261 ],\n",
       "       [0.5309259 ],\n",
       "       [0.53092635],\n",
       "       [0.5309248 ],\n",
       "       [0.5309257 ],\n",
       "       [0.53092587],\n",
       "       [0.5309261 ],\n",
       "       [0.53092647],\n",
       "       [0.5309253 ],\n",
       "       [0.530926  ],\n",
       "       [0.5309255 ],\n",
       "       [0.5309271 ],\n",
       "       [0.5309248 ],\n",
       "       [0.53092617],\n",
       "       [0.5309251 ],\n",
       "       [0.5309266 ],\n",
       "       [0.5309236 ],\n",
       "       [0.53092504],\n",
       "       [0.53092664],\n",
       "       [0.53092647],\n",
       "       [0.53092706],\n",
       "       [0.5309231 ],\n",
       "       [0.5309255 ],\n",
       "       [0.5309251 ],\n",
       "       [0.5309267 ],\n",
       "       [0.5309255 ],\n",
       "       [0.5309244 ],\n",
       "       [0.53092504],\n",
       "       [0.53092575],\n",
       "       [0.5309266 ],\n",
       "       [0.53092605],\n",
       "       [0.5309262 ],\n",
       "       [0.5309267 ],\n",
       "       [0.5309276 ],\n",
       "       [0.5309242 ],\n",
       "       [0.5309245 ],\n",
       "       [0.530926  ],\n",
       "       [0.5309248 ],\n",
       "       [0.5309267 ],\n",
       "       [0.5309267 ],\n",
       "       [0.5309251 ],\n",
       "       [0.53092515],\n",
       "       [0.53092635],\n",
       "       [0.5309255 ],\n",
       "       [0.5309259 ],\n",
       "       [0.5309264 ],\n",
       "       [0.5309274 ],\n",
       "       [0.53092706],\n",
       "       [0.5309255 ],\n",
       "       [0.5309266 ],\n",
       "       [0.53092676],\n",
       "       [0.5309256 ],\n",
       "       [0.530927  ],\n",
       "       [0.5309262 ],\n",
       "       [0.5309263 ],\n",
       "       [0.5309248 ],\n",
       "       [0.530926  ],\n",
       "       [0.5309259 ],\n",
       "       [0.53092647],\n",
       "       [0.53092647],\n",
       "       [0.53092694],\n",
       "       [0.5309263 ],\n",
       "       [0.5309236 ],\n",
       "       [0.53092504],\n",
       "       [0.53092664],\n",
       "       [0.53092647],\n",
       "       [0.53092706],\n",
       "       [0.5309231 ],\n",
       "       [0.5309255 ],\n",
       "       [0.5309251 ],\n",
       "       [0.5309267 ],\n",
       "       [0.5309255 ],\n",
       "       [0.5309244 ],\n",
       "       [0.53092504],\n",
       "       [0.53092575],\n",
       "       [0.5309266 ],\n",
       "       [0.53092605],\n",
       "       [0.5309262 ],\n",
       "       [0.5309267 ],\n",
       "       [0.5309276 ],\n",
       "       [0.5309242 ],\n",
       "       [0.5309245 ],\n",
       "       [0.530926  ],\n",
       "       [0.5309248 ],\n",
       "       [0.5309267 ],\n",
       "       [0.5309267 ],\n",
       "       [0.5309251 ],\n",
       "       [0.53092515],\n",
       "       [0.53092635],\n",
       "       [0.5309255 ],\n",
       "       [0.5309259 ],\n",
       "       [0.5309264 ],\n",
       "       [0.5309274 ],\n",
       "       [0.53092706],\n",
       "       [0.5309255 ],\n",
       "       [0.5309264 ],\n",
       "       [0.5309268 ],\n",
       "       [0.5309254 ],\n",
       "       [0.53092694],\n",
       "       [0.530926  ],\n",
       "       [0.5309262 ],\n",
       "       [0.53092545],\n",
       "       [0.53092575],\n",
       "       [0.530926  ],\n",
       "       [0.53092605],\n",
       "       [0.53092635],\n",
       "       [0.53092676],\n",
       "       [0.5309266 ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict([query_padded, likes_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194c6f1-1e76-4c27-a4b0-3dabec35d5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1848cd38-fa13-42cb-bbb3-fcde1e27b918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence\n",
      "23 23\n",
      "Quantum mechanics\n",
      "17 17\n",
      "Renewable energy\n",
      "16 16\n",
      "Machine learning\n",
      "16 16\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    q = data['query'][i]\n",
    "    print(q)\n",
    "    seq = tokenizer.texts_to_sequences(q)\n",
    "    pad = pad_sequences(seq)\n",
    "    print(len(seq), len(pad))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9beb5-594b-4638-9fde-529e68a68c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a68506cd-1a02-43a9-b9b0-e03969048b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(['sleep', 'hello', 'good', 'bb'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fdabb011-9708-4aaa-9c6e-ff6aeca5ffc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1]]\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Tokenizer\", \"config\": {\"num_words\": 10000, \"filters\": \"!\\\\\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n\", \"lower\": true, \"split\": \" \", \"char_level\": false, \"oov_token\": \"<OOV>\", \"document_count\": 4, \"word_counts\": \"{\\\\\"sleep\\\\\": 1, \\\\\"hello\\\\\": 1, \\\\\"good\\\\\": 1, \\\\\"bb\\\\\": 1}\", \"word_docs\": \"{\\\\\"sleep\\\\\": 1, \\\\\"hello\\\\\": 1, \\\\\"good\\\\\": 1, \\\\\"bb\\\\\": 1}\", \"index_docs\": \"{\\\\\"2\\\\\": 1, \\\\\"3\\\\\": 1, \\\\\"4\\\\\": 1, \\\\\"5\\\\\": 1}\", \"index_word\": \"{\\\\\"1\\\\\": \\\\\"baddddjjkj\\\\\", \\\\\"2\\\\\": \\\\\"sleep\\\\\", \\\\\"3\\\\\": \\\\\"hello\\\\\", \\\\\"4\\\\\": \\\\\"good\\\\\", \\\\\"5\\\\\": \\\\\"bb\\\\\"}\", \"word_index\": \"{\\\\\"<OOV>\\\\\": 1, \\\\\"sleep\\\\\": 2, \\\\\"hello\\\\\": 3, \\\\\"good\\\\\": 4, \\\\\"bb\\\\\": 5, \\\\\"baddddjjkj\\\\\": 1}\"}}'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.texts_to_sequences(['good baddddjjkj']))\n",
    "print(tokenizer.document_count)\n",
    "tokenizer.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "747df5eb-5a84-4b20-8dc5-c5bf50f0e828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [1]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['better', 'sleeping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329be0c5-b948-413a-9a33-e8f6e7a43f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c129e4c1-54f8-4b29-9795-afc27b0ed703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3\n",
      "Tokenized sequences: [[1], [2]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the text containing the words\n",
    "texts = [\"sleeping\", \"sleep\"]\n",
    "\n",
    "# Initialize Tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "# Fit tokenizer on texts\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Tokenize the texts\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# Check vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary size:\", vocab_size)\n",
    "\n",
    "# Print the tokenized sequences\n",
    "print(\"Tokenized sequences:\", sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5405d7b3-f8bf-4bd3-9c8c-da5a8a869cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4263b7fc-8ada-43e2-93ca-6d5864bf8dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1355e-1549-4a3d-957e-95f859ec0016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9251ed5b-9fd4-46c4-b0fb-60b590e9ba64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bccd34-098c-44f5-8bd6-0ed0def05577",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Define the LSTM model architecture\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m----> 6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mEmbedding(vocab_size, \u001b[43membedding_size\u001b[49m))\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTM(lstm_units))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ... (additional layers)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_size' is not defined"
     ]
    }
   ],
   "source": [
    "# using LSTM\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, embedding_size))\n",
    "model.add(keras.layers.LSTM(lstm_units))\n",
    "# ... (additional layers)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train the model on historical user search data\n",
    "model.fit(user_search_sequences, target_sequences, epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d49f420-a055-46fe-906a-e73423ee1b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_KEY =\"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae8c0e70-d0b1-4ce1-b978-718ebddb8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12208df6-4570-4bd9-a310-7f6cb32f263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data of user search history and liked keywords\n",
    "user_search_history = [\n",
    "    \"deep learning\", \"neural networks\", \"natural language processing\", \"image recognition\",\n",
    "    \"machine learning\", \"text classification\", \"sentiment analysis\", \"data visualization\"\n",
    "]\n",
    "liked_keywords = [\"neural networks\", \"natural language processing\", \"text classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1fb934c8-de50-428d-ac4e-d9757c23999b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep',\n",
       " 'learning',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'image',\n",
       " 'recognition',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'text',\n",
       " 'classification',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'data',\n",
       " 'visualization']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize user search history and create a vocabulary\n",
    "tokenized_history = [token.text.lower() for query in user_search_history for token in nlp(query)]\n",
    "vocab = Counter(tokenized_history)\n",
    "tokenized_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab3e58c7-8523-47ea-9480-e38f69bc7f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract keywords from user input\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    keywords = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63ea77d4-6a96-4fe9-bd63-58968ede5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map words to indices for encoding\n",
    "word_to_index = {word: index for index, (word, _) in enumerate(vocab.items())}\n",
    "index_to_word = {index: word for word, index in word_to_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c11d9f42-2248-4458-ab30-7617093e12d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deep': 0, 'learning': 1, 'neural': 2, 'networks': 3, 'natural': 4, 'language': 5, 'processing': 6, 'image': 7, 'recognition': 8, 'machine': 9, 'text': 10, 'classification': 11, 'sentiment': 12, 'analysis': 13, 'data': 14, 'visualization': 15}\n",
      "{0: 'deep', 1: 'learning', 2: 'neural', 3: 'networks', 4: 'natural', 5: 'language', 6: 'processing', 7: 'image', 8: 'recognition', 9: 'machine', 10: 'text', 11: 'classification', 12: 'sentiment', 13: 'analysis', 14: 'data', 15: 'visualization'}\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index)\n",
    "print(index_to_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f769de97-5ba6-4a58-b011-f88b5effe698",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Embedding: {'input_length': 1000}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m index_to_word \u001b[38;5;241m=\u001b[39m {index: word \u001b[38;5;28;01mfor\u001b[39;00m word, index \u001b[38;5;129;01min\u001b[39;00m word_to_index\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define the neural network model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      8\u001b[0m     layers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[1;32m      9\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     10\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m ])\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/personal/major project/backend/env/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:81\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, embeddings_constraint, mask_zero, lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     72\u001b[0m     input_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     80\u001b[0m ):\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim \u001b[38;5;241m=\u001b[39m input_dim\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim \u001b[38;5;241m=\u001b[39m output_dim\n",
      "File \u001b[0;32m~/Projects/personal/major project/backend/env/lib/python3.12/site-packages/keras/src/layers/layer.py:265\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_policy \u001b[38;5;241m=\u001b[39m dtype_policies\u001b[38;5;241m.\u001b[39mget(dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Embedding: {'input_length': 1000}"
     ]
    }
   ],
   "source": [
    "\n",
    "# Map words to indices for encoding\n",
    "word_to_index = {word: index for index, (word, _) in enumerate(vocab.items())}\n",
    "index_to_word = {index: word for word, index in word_to_index.items()}\n",
    "\n",
    "# Define the neural network model\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=len(vocab), output_dim=128, input_length = 1000),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "# Now you can use this trained model to prioritize user search results based on previously liked keywords.\n",
    "# Given a new search query, tokenize it, convert to indices, and pass it through the model to get the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6acb45ab-fc19-47a5-a125-4d500dcd5c91",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Prepare data for training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword_to_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muser_search_history\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(word \u001b[38;5;129;01min\u001b[39;00m liked_keywords \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m nlp(query)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m user_search_history])\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "X = np.array([[word_to_index[token.text.lower()] for token in nlp(query)] for query in user_search_history])\n",
    "y = np.array([1 if any(word in liked_keywords for word in nlp(query)) else 0 for query in user_search_history])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b968bfef-7634-4927-a0ca-1afa46ef6ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.05279589  0.43462123  0.56446557 ... -0.21558542 -0.48716266\n",
      "  -0.32593815]\n",
      " [-0.18021194  0.88805299  0.10379477 ...  0.54008547 -0.65012576\n",
      "  -0.77059586]\n",
      " ...\n",
      " [-0.14913941  0.18610728 -0.70102764 ... -0.96837596  0.344502\n",
      "   0.22158446]\n",
      " [ 0.60155447 -0.26443112 -0.05675138 ...  0.68479661 -0.41752299\n",
      "   0.18084771]\n",
      " [-0.06753045 -0.92260275  0.30947412 ...  0.33175464 -0.66563538\n",
      "   0.5770741 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Sample text input\n",
    "text_input = [\n",
    "    \"This is an example sentence.\",\n",
    "    \"Another example sentence with more words.\",\n",
    "    \"Yet another sentence to demonstrate word embeddings.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5ad97bc-da5f-4e79-8d80-7a5e0d5962cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 1, 'example': 2, 'another': 3, 'this': 4, 'is': 5, 'an': 6, 'with': 7, 'more': 8, 'words': 9, 'yet': 10, 'to': 11, 'demonstrate': 12, 'word': 13, 'embeddings': 14}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize the text input\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_input)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "dir(tokenizer)\n",
    "print(tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79a42b4a-198d-41bb-9166-a86b2f559157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert text to sequences and pad sequences to a fixed length\n",
    "sequences = tokenizer.texts_to_sequences(text_input)\n",
    "max_length = max(len(sequence) for sequence in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97781187-1d74-45d2-a882-fa3b5ab6c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create word embedding matrix\n",
    "embedding_dim = 100  # You can adjust this dimension as needed\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = np.random.uniform(-1, 1, embedding_dim)  # Random initialization\n",
    "    embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "177f9dad-ef9b-4656-816b-2f1f2566e6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.64894336 -0.96631378 -0.51312237 ... -0.10282251 -0.6012645\n",
      "  -0.33397218]\n",
      " [-0.71462387 -0.45171066  0.6505204  ... -0.51602674 -0.56520368\n",
      "   0.35719344]\n",
      " ...\n",
      " [ 0.17553115 -0.79921191 -0.85921446 ... -0.83543187  0.2561677\n",
      "   0.58636922]\n",
      " [-0.11079464 -0.66227062 -0.93281072 ...  0.5700236   0.79761942\n",
      "  -0.9838077 ]\n",
      " [ 0.01833037 -0.94100712 -0.97003552 ... -0.23840626  0.17142113\n",
      "  -0.79295537]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print word embedding array\n",
    "print(embedding_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025c178-de06-40ce-89bd-dab461d63bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
